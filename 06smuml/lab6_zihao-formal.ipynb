{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This data set was created by IBM data scientists.  It describes 35 features for 1470 (fictional) employees including whether or not the employee has left the firm (labeled \"attrition\" in the dataset).  Employees leave companies for a variety of reasons: disatisfaction with their role, their manager or their pay.  Perhaps they aren't necessarily dissatified with their current job but feel like something better is out there.  Or maybe they just feel like they'd been there long enough, and want something different. Most likely its a combination of all of these things, plus a few others.  \n",
    "\n",
    "Employers would like to have a sense of why and when an employee might leave.  If an employer believes that an employee that they really value might leave, they could respond and try to prevent them from leaving.  This is what we will attempt to predict using a wide and deep neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1392</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>591</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
       "0   41       Yes      Travel_Rarely       1102                   Sales   \n",
       "1   49        No  Travel_Frequently        279  Research & Development   \n",
       "2   37       Yes      Travel_Rarely       1373  Research & Development   \n",
       "3   33        No  Travel_Frequently       1392  Research & Development   \n",
       "4   27        No      Travel_Rarely        591  Research & Development   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EmployeeCount  EmployeeNumber  \\\n",
       "0                 1          2  Life Sciences              1               1   \n",
       "1                 8          1  Life Sciences              1               2   \n",
       "2                 2          2          Other              1               4   \n",
       "3                 3          4  Life Sciences              1               5   \n",
       "4                 2          1        Medical              1               7   \n",
       "\n",
       "           ...           RelationshipSatisfaction StandardHours  \\\n",
       "0          ...                                  1            80   \n",
       "1          ...                                  4            80   \n",
       "2          ...                                  2            80   \n",
       "3          ...                                  3            80   \n",
       "4          ...                                  4            80   \n",
       "\n",
       "   StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  \\\n",
       "0                 0                  8                      0               1   \n",
       "1                 1                 10                      3               3   \n",
       "2                 0                  7                      3               3   \n",
       "3                 0                  8                      3               3   \n",
       "4                 1                  6                      3               3   \n",
       "\n",
       "   YearsAtCompany YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
       "0               6                  4                        0   \n",
       "1              10                  7                        1   \n",
       "2               0                  0                        0   \n",
       "3               8                  7                        3   \n",
       "4               2                  2                        2   \n",
       "\n",
       "   YearsWithCurrManager  \n",
       "0                     5  \n",
       "1                     7  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     2  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/'\n",
    "df = pd.read_csv(os.path.join(data_path, 'WA_Fn-UseC_-HR-Employee-Attrition.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expansion\n",
    "\n",
    "This is a relative small dataset with only 1470 data rows. We want more data to train and test. For data expension, we will try several ways to do so. And first we are going to copy and append some rows to origin dataset and expand it to 2000 rows.\n",
    "For another attempt, we take numberical datas from the raw dataframe slice, and add some randomly generat noise to these numerical data. Then we insert categorical data rows back to the dataframe of numerical data with random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_slice = df[:530]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = df.append(df_slice)\n",
    "df_new = df_new.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_slice2 = df_slice[['Age','DistanceFromHome','Education','EnvironmentSatisfaction',\n",
    "                      'JobSatisfaction','MonthlyIncome','PerformanceRating','RelationshipSatisfaction',\n",
    "                      'TotalWorkingYears','YearsAtCompany']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use df_slice2 to take numberical datas from the raw dataframe slice, and add some randomly generated noise to these numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slice2 = df_slice2 * (1 + np.random.uniform(-0.01,0.01,(df_slice2.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_slice2.insert(1, 'Attrition', df_slice['Attrition'])\n",
    "df_slice2.insert(2, 'Department', df_slice['Department'])\n",
    "df_slice2.insert(6, 'Gender', df_slice['Gender'])\n",
    "df_slice2.insert(8, 'MaritalStatus', df_slice['MaritalStatus'])\n",
    "df_slice2.insert(10, 'OverTime', df_slice['OverTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new2 = df.append(df_slice2)\n",
    "df_new2 = df_new2.reset_index(drop=True)\n",
    "df = df_new2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a dataframe with 2000 rows and 15 clomuns expanded dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 35 features in total in the dataset, but we don't want to use all of them.  \n",
    "Let's focus on a few of them:\n",
    "- Age\n",
    "- Attrition \n",
    "- Department\n",
    "- DistanceFromHome \n",
    "- Education \n",
    "- EduacationField\n",
    "- EnvironmentSatisfaction\n",
    "- Gender\n",
    "- JobSatisfaction\n",
    "- MaritalStatus\n",
    "- MonthlyIncome\n",
    "- OverTime\n",
    "- PerformanceRating\n",
    "- RelationshipSatisfaction\n",
    "- TotalWorkingYears\n",
    "- YearsAtCompany\n",
    "- YearsSinceLastPromotion\n",
    "\n",
    "These features are what we believe important to predict the attrition status. \n",
    "We will use attrition as our label.\n",
    "\n",
    "So let's first drop the other features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 15 columns):\n",
      "Age                         2000 non-null float64\n",
      "Attrition                   2000 non-null object\n",
      "Department                  2000 non-null object\n",
      "DistanceFromHome            2000 non-null float64\n",
      "Education                   2000 non-null float64\n",
      "EnvironmentSatisfaction     2000 non-null float64\n",
      "Gender                      2000 non-null object\n",
      "JobSatisfaction             2000 non-null float64\n",
      "MaritalStatus               2000 non-null object\n",
      "MonthlyIncome               2000 non-null float64\n",
      "OverTime                    2000 non-null object\n",
      "PerformanceRating           2000 non-null float64\n",
      "RelationshipSatisfaction    2000 non-null float64\n",
      "TotalWorkingYears           2000 non-null float64\n",
      "YearsAtCompany              2000 non-null float64\n",
      "dtypes: float64(10), object(5)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "to_keep = {'Age', 'Attrition', 'Department','DistanceFromHome', 'Education', 'EnvironmentSatisfaction', 'Gender', 'JobSatisfaction', 'MaritalStatus',\n",
    "           'MonthlyIncome', 'OverTime', 'PerformanceRating', 'RelationshipSatisfaction','TotalWorkingYears','YearsAtCompany'}\n",
    "to_drop = set(df.columns)-to_keep\n",
    "df.drop(to_drop, axis=1, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's good that we don't have any null value. Let's encode the categorical data to ints. There are some categorical values those have been encoded once from the origin and transfered to type int. We want to use some of them for the cross features, so we want to transfer their type to string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_convert = ['Education','EnvironmentSatisfaction','JobSatisfaction',\n",
    "            'PerformanceRating','RelationshipSatisfaction']\n",
    "for col in to_convert:\n",
    "    df[col] = df[col].astype(np.str) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "to_encode = {'Attrition', 'Department','Gender','MaritalStatus','OverTime','Education','EnvironmentSatisfaction','JobSatisfaction',\n",
    "            'PerformanceRating','RelationshipSatisfaction'}\n",
    "encoders = dict()\n",
    "\n",
    "for col in to_encode:\n",
    "    if col==\"attrition\":\n",
    "        tmp = LabelEncoder()\n",
    "        df[col] = tmp.fit_transform(df[col])\n",
    "    else:\n",
    "        encoders[col] = LabelEncoder()\n",
    "        df[col+'_int'] = encoders[col].fit_transform(df[col])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's scale the numeric features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_features =list(to_encode)\n",
    "categorical_features = [x+'_int' for x in categorical_features]\n",
    "numerics = set(df.columns) - to_encode\n",
    "numerics = list(numerics - set(categorical_features))\n",
    "\n",
    "for atr in numerics:\n",
    "    df[atr] = df[atr].astype(np.float)    \n",
    "    ss = StandardScaler()\n",
    "    df[atr] = ss.fit_transform(df[atr].values.reshape(-1, 1))\n",
    "    \n",
    "feature_columns = categorical_features + numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 25 columns):\n",
      "Age                             2000 non-null float64\n",
      "Attrition                       2000 non-null object\n",
      "Department                      2000 non-null object\n",
      "DistanceFromHome                2000 non-null float64\n",
      "Education                       2000 non-null object\n",
      "EnvironmentSatisfaction         2000 non-null object\n",
      "Gender                          2000 non-null object\n",
      "JobSatisfaction                 2000 non-null object\n",
      "MaritalStatus                   2000 non-null object\n",
      "MonthlyIncome                   2000 non-null float64\n",
      "OverTime                        2000 non-null object\n",
      "PerformanceRating               2000 non-null object\n",
      "RelationshipSatisfaction        2000 non-null object\n",
      "TotalWorkingYears               2000 non-null float64\n",
      "YearsAtCompany                  2000 non-null float64\n",
      "PerformanceRating_int           2000 non-null int64\n",
      "Gender_int                      2000 non-null int64\n",
      "Department_int                  2000 non-null int64\n",
      "RelationshipSatisfaction_int    2000 non-null int64\n",
      "MaritalStatus_int               2000 non-null int64\n",
      "Attrition_int                   2000 non-null int64\n",
      "OverTime_int                    2000 non-null int64\n",
      "EnvironmentSatisfaction_int     2000 non-null int64\n",
      "Education_int                   2000 non-null int64\n",
      "JobSatisfaction_int             2000 non-null int64\n",
      "dtypes: float64(5), int64(10), object(10)\n",
      "memory usage: 390.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data is ready to split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (1800, 15) test (200, 15)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Input\n",
    "from keras.layers import Embedding, Flatten, Merge, concatenate\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# stratified 90/10 train/test split`\n",
    "df_train, df_test = train_test_split(df, test_size=0.1, stratify=df.Attrition)\n",
    "\n",
    "X_train = ss.fit_transform(df_train[feature_columns].values).astype(np.float32)\n",
    "X_test = ss.fit_transform(df_test[feature_columns].values).astype(np.float32)\n",
    "\n",
    "y_train = df_train['Attrition_int'].values.astype(np.int)\n",
    "y_test = df_test['Attrition_int'].values.astype(np.int)\n",
    "\n",
    "print('train', X_train.shape, 'test', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "X_train_ohe = ohe.fit_transform(df_train[categorical_features].values)\n",
    "X_test_ohe = ohe.transform(df_test[categorical_features].values)\n",
    "\n",
    "\n",
    "X_train_num =  df_train[numerics].values\n",
    "X_test_num = df_test[numerics].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_columns = [['Gender','MaritalStatus'],\n",
    "                    ['Education', 'JobSatisfaction'],['Department','PerformanceRating'],\n",
    "                    ['Education', 'JobSatisfaction','RelationshipSatisfaction'],['Department','OverTime'],\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 3s 2ms/step - loss: 0.1530 - acc: 0.8289\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 0s 160us/step - loss: 0.1020 - acc: 0.8572\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 0s 166us/step - loss: 0.0476 - acc: 0.9589\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 0s 158us/step - loss: 0.0118 - acc: 0.9978\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 0s 156us/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 0s 137us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 0s 182us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 0s 191us/step - loss: 7.6979e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 0s 162us/step - loss: 6.1079e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x262a9545be0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# we need to create separate sequential models for each embedding\n",
    "embed_branches = []\n",
    "X_ints_train = []\n",
    "X_ints_test = []\n",
    "all_inputs = []\n",
    "all_branch_outputs = []\n",
    "\n",
    "for cols in cross_columns:\n",
    "    # encode crossed columns as ints for the embedding\n",
    "    enc = LabelEncoder()\n",
    "    \n",
    "    # create crossed labels\n",
    "    # needs to be commented better, Eric!\n",
    "    X_crossed_train = df_train[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "    X_crossed_test = df_test[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "    \n",
    "    enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "    X_crossed_train = enc.transform(X_crossed_train)\n",
    "    X_crossed_test = enc.transform(X_crossed_test)\n",
    "    X_ints_train.append( X_crossed_train )\n",
    "    X_ints_test.append( X_crossed_test )\n",
    "    \n",
    "    # get the number of categories\n",
    "    N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "    \n",
    "    # create embedding branch from the number of categories\n",
    "    inputs = Input(shape=(1,),dtype='int32', name = '_'.join(cols))\n",
    "    all_inputs.append(inputs)\n",
    "    x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "    x = Flatten()(x)\n",
    "    all_branch_outputs.append(x)\n",
    "    \n",
    "# merge the branches together\n",
    "wide_branch = concatenate(all_branch_outputs)\n",
    "\n",
    "# reset this input branch\n",
    "all_branch_outputs = []\n",
    "# add in the embeddings\n",
    "for col in categorical_features:\n",
    "    # encode as ints for the embedding\n",
    "    X_ints_train.append( df_train[col].values )\n",
    "    X_ints_test.append( df_test[col].values )\n",
    "    \n",
    "    # get the number of categories\n",
    "    N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "    \n",
    "    # create embedding branch from the number of categories\n",
    "    inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "    all_inputs.append(inputs)\n",
    "    x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "    x = Flatten()(x)\n",
    "    all_branch_outputs.append(x)\n",
    "    \n",
    "# also get a dense branch of the numeric features\n",
    "all_inputs.append(Input(shape=(X_train_num.shape[1],),sparse=False,name='numeric_data'))\n",
    "x = Dense(units=20, activation='relu')(all_inputs[-1])\n",
    "all_branch_outputs.append( x )\n",
    "\n",
    "# merge the branches together\n",
    "deep_branch = concatenate(all_branch_outputs)\n",
    "deep_branch = Dense(units=50,activation='relu')(deep_branch)\n",
    "deep_branch = Dense(units=10,activation='relu')(deep_branch)\n",
    "    \n",
    "final_branch = concatenate([wide_branch, deep_branch])\n",
    "final_branch = Dense(units=1,activation='sigmoid')(final_branch)\n",
    "\n",
    "model = Model(inputs=all_inputs, outputs=final_branch)\n",
    "\n",
    "model.compile(optimizer='adagrad',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_ints_train+ [X_train_num],\n",
    "        y_train, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[168   0]\n",
      " [  0  32]] 1.0\n"
     ]
    }
   ],
   "source": [
    "yhat = np.round(model.predict(X_ints_test + [X_test_num]))\n",
    "print(mt.confusion_matrix(y_test,yhat),mt.accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
