{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1392</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>591</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
       "0   41       Yes      Travel_Rarely       1102                   Sales   \n",
       "1   49        No  Travel_Frequently        279  Research & Development   \n",
       "2   37       Yes      Travel_Rarely       1373  Research & Development   \n",
       "3   33        No  Travel_Frequently       1392  Research & Development   \n",
       "4   27        No      Travel_Rarely        591  Research & Development   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EmployeeCount  EmployeeNumber  \\\n",
       "0                 1          2  Life Sciences              1               1   \n",
       "1                 8          1  Life Sciences              1               2   \n",
       "2                 2          2          Other              1               4   \n",
       "3                 3          4  Life Sciences              1               5   \n",
       "4                 2          1        Medical              1               7   \n",
       "\n",
       "           ...           RelationshipSatisfaction StandardHours  \\\n",
       "0          ...                                  1            80   \n",
       "1          ...                                  4            80   \n",
       "2          ...                                  2            80   \n",
       "3          ...                                  3            80   \n",
       "4          ...                                  4            80   \n",
       "\n",
       "   StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  \\\n",
       "0                 0                  8                      0               1   \n",
       "1                 1                 10                      3               3   \n",
       "2                 0                  7                      3               3   \n",
       "3                 0                  8                      3               3   \n",
       "4                 1                  6                      3               3   \n",
       "\n",
       "   YearsAtCompany YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
       "0               6                  4                        0   \n",
       "1              10                  7                        1   \n",
       "2               0                  0                        0   \n",
       "3               8                  7                        3   \n",
       "4               2                  2                        2   \n",
       "\n",
       "   YearsWithCurrManager  \n",
       "0                     5  \n",
       "1                     7  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     2  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/'\n",
    "df = pd.read_csv(os.path.join(data_path, 'WA_Fn-UseC_-HR-Employee-Attrition.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 35 features in total in the dataset about. \n",
    "Let's focus on a few of them:\n",
    "- Age\n",
    "- Attrition\n",
    "- Department\n",
    "- DistanceFromHome\n",
    "- Education\n",
    "- EnvironmentSatisfaction\n",
    "- Gender\n",
    "- JobSatisfaction\n",
    "- MaritalStatus\n",
    "- MonthlyIncome\n",
    "- OverTime\n",
    "- PerformanceRating\n",
    "- RelationshipSatisfaction\n",
    "- TotalWorkingYears\n",
    "- YearsAtCompany\n",
    "\n",
    "In this lab, we will use attrition as our label, to try to predict the attrition status accroding to other attributes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1470 entries, 0 to 1469\n",
      "Data columns (total 15 columns):\n",
      "Age                         1470 non-null int64\n",
      "Attrition                   1470 non-null object\n",
      "Department                  1470 non-null object\n",
      "DistanceFromHome            1470 non-null int64\n",
      "Education                   1470 non-null int64\n",
      "EnvironmentSatisfaction     1470 non-null int64\n",
      "Gender                      1470 non-null object\n",
      "JobSatisfaction             1470 non-null int64\n",
      "MaritalStatus               1470 non-null object\n",
      "MonthlyIncome               1470 non-null int64\n",
      "OverTime                    1470 non-null object\n",
      "PerformanceRating           1470 non-null int64\n",
      "RelationshipSatisfaction    1470 non-null int64\n",
      "TotalWorkingYears           1470 non-null int64\n",
      "YearsAtCompany              1470 non-null int64\n",
      "dtypes: int64(10), object(5)\n",
      "memory usage: 172.3+ KB\n"
     ]
    }
   ],
   "source": [
    "to_keep = {'Age', 'Attrition', 'Department','DistanceFromHome', 'Education', 'EnvironmentSatisfaction', 'Gender', 'JobSatisfaction', 'MaritalStatus',\n",
    "           'MonthlyIncome', 'OverTime', 'PerformanceRating', 'RelationshipSatisfaction','TotalWorkingYears','YearsAtCompany'}\n",
    "to_drop = set(df.columns)-to_keep\n",
    "df.drop(to_drop, axis=1, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's good that we don't have any null value. Let's one hot encode the Attrition, Department, Gender, MaritalStatus and Overtime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "to_encode = {'Attrition', 'Department','Gender','MaritalStatus','OverTime'}\n",
    "encoders = dict()\n",
    "\n",
    "for atr in to_encode:\n",
    "    encoders[atr] = LabelEncoder()\n",
    "    df[atr] = encoders[atr].fit_transform(df[atr] )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's scale the numeric features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerics = set(df.columns) - to_encode\n",
    "for atr in numerics:\n",
    "    df[atr] = df[atr].astype(np.float)    \n",
    "    ss = StandardScaler()\n",
    "    df[atr] = ss.fit_transform(df[atr].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1470 entries, 0 to 1469\n",
      "Data columns (total 15 columns):\n",
      "Age                         1470 non-null float64\n",
      "Attrition                   1470 non-null int64\n",
      "Department                  1470 non-null int64\n",
      "DistanceFromHome            1470 non-null float64\n",
      "Education                   1470 non-null float64\n",
      "EnvironmentSatisfaction     1470 non-null float64\n",
      "Gender                      1470 non-null int64\n",
      "JobSatisfaction             1470 non-null float64\n",
      "MaritalStatus               1470 non-null int64\n",
      "MonthlyIncome               1470 non-null float64\n",
      "OverTime                    1470 non-null int64\n",
      "PerformanceRating           1470 non-null float64\n",
      "RelationshipSatisfaction    1470 non-null float64\n",
      "TotalWorkingYears           1470 non-null float64\n",
      "YearsAtCompany              1470 non-null float64\n",
      "dtypes: float64(10), int64(5)\n",
      "memory usage: 172.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_features = [('Age','MaritalStatus'),('Age','Gender'),('Department','MonthlyIncome'),('Department','YearsAtCompany'),('Age','TotalWorkingYears'),\n",
    "                    ('Education', 'JobSatisfaction'),('Age','DistanceFromHome'),('Department','PerformanceRating','MonthlyIncome'),\n",
    "                    ('Education', 'JobSatisfaction','RelationshipSatisfaction'),('Department','OverTime','YearsAtCompany'),\n",
    "                    ('Age','TotalWorkingYears','YearsAtCompany')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (1323, 14) test (147, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# stratified 90/10 train/test split`\n",
    "df_train, df_test = train_test_split(df, test_size=0.1, stratify=df.Attrition)\n",
    "\n",
    "y_train = df_train.Attrition\n",
    "y_test = df_test.Attrition\n",
    "\n",
    "X_train = df_train.drop('Attrition', axis=1).values\n",
    "X_test = df_test.drop('Attrition', axis=1).values\n",
    "\n",
    "print('train', X_train.shape, 'test', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial test (Categorical not encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Input\n",
    "from keras.layers import Embedding, Flatten, Merge, concatenate\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_features = list(to_encode)\n",
    "numerics = list(numerics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(X_train.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(units=10, activation='relu')(inputs)\n",
    "predictions = Dense(1,activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                150       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[82 41]\n",
      " [19  5]] 0.591836734694\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics as mt\n",
    "yhat = np.round(model.predict(X_test))\n",
    "print(mt.confusion_matrix(y_test,yhat),mt.accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Encoded categorical features test only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "X_train_ohe = ohe.fit_transform(df_train[categorical_features].values)\n",
    "X_test_ohe = ohe.transform(df_test[categorical_features].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[123   0]\n",
      " [ 12  12]] 0.918367346939\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(X_train_ohe.shape[1],),sparse=True)\n",
    "\n",
    "x = Dense(units=10, activation='relu')(inputs)\n",
    "predictions = Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_ohe,y_train, epochs=10, batch_size=50, verbose=0)\n",
    "\n",
    "yhat = np.round(model.predict(X_test_ohe))\n",
    "print(mt.confusion_matrix(y_test,yhat),mt.accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense, Sparce and Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           130         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           110         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 20)           0           dense_5[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            21          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 261\n",
      "Trainable params: 261\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ohe = OneHotEncoder()\n",
    "X_train_ohe = ohe.fit_transform(df_train[categorical_features].values)\n",
    "X_test_ohe = ohe.transform(df_test[categorical_features].values)\n",
    "\n",
    "\n",
    "X_train_num =  df_train[numerics].values\n",
    "X_test_num = df_test[numerics].values\n",
    "\n",
    "\n",
    "inputsSparse = Input(shape=(X_train_ohe.shape[1],),sparse=True)\n",
    "xSparse = Dense(units=10, activation='relu')(inputsSparse)\n",
    "\n",
    "\n",
    "inputsDense = Input(shape=(X_train_num.shape[1],),sparse=False)\n",
    "xDense = Dense(units=10, activation='relu')(inputsDense)\n",
    "\n",
    "x = concatenate([xSparse, xDense])\n",
    "predictions = Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and Dense layers\n",
    "model = Model(inputs=[inputsSparse,inputsDense], outputs=predictions)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[122   1]\n",
      " [ 23   1]] 0.836734693878\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit([X_train_ohe,X_train_num],y_train, epochs=10, batch_size=50, verbose=0)\n",
    "\n",
    "yhat = np.round(model.predict([X_test_ohe,X_test_num]))\n",
    "print(mt.confusion_matrix(y_test,yhat),mt.accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Embeddings and Deep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1323/1323 [==============================] - 0s 211us/step - loss: 0.2486 - acc: 0.5903\n",
      "Epoch 2/10\n",
      "1323/1323 [==============================] - 0s 28us/step - loss: 0.2199 - acc: 0.6954\n",
      "Epoch 3/10\n",
      "1323/1323 [==============================] - 0s 28us/step - loss: 0.1999 - acc: 0.7581\n",
      "Epoch 4/10\n",
      "1323/1323 [==============================] - 0s 28us/step - loss: 0.1857 - acc: 0.7785\n",
      "Epoch 5/10\n",
      "1323/1323 [==============================] - 0s 28us/step - loss: 0.1751 - acc: 0.7997\n",
      "Epoch 6/10\n",
      "1323/1323 [==============================] - 0s 28us/step - loss: 0.1672 - acc: 0.8141\n",
      "Epoch 7/10\n",
      "1323/1323 [==============================] - 0s 29us/step - loss: 0.1614 - acc: 0.8224\n",
      "Epoch 8/10\n",
      "1323/1323 [==============================] - 0s 28us/step - loss: 0.1567 - acc: 0.8299\n",
      "Epoch 9/10\n",
      "1323/1323 [==============================] - 0s 27us/step - loss: 0.1529 - acc: 0.8337\n",
      "Epoch 10/10\n",
      "1323/1323 [==============================] - 0s 29us/step - loss: 0.1497 - acc: 0.8360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24c5a97e780>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to create separate sequential models for each embedding\n",
    "embed_branches = []\n",
    "X_ints_train = []\n",
    "X_ints_test = []\n",
    "all_inputs = []\n",
    "all_branch_outputs = []\n",
    "\n",
    "for col in categorical_features:\n",
    "    # encode as ints for the embedding\n",
    "    X_ints_train.append( df_train[col].values )\n",
    "    X_ints_test.append( df_test[col].values )\n",
    "    \n",
    "    # get the number of categories\n",
    "    N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "    \n",
    "    # create embedding branch from the number of categories\n",
    "    inputs = Input(shape=(1,),dtype='int32')\n",
    "    all_inputs.append(inputs)\n",
    "    x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "    x = Flatten()(x)\n",
    "    all_branch_outputs.append(x)\n",
    "\n",
    "# also get a dense branch of the numeric features\n",
    "all_inputs.append(Input(shape=(X_train_num.shape[1],),sparse=False))\n",
    "x = Dense(units=20, activation='relu')(all_inputs[-1])\n",
    "all_branch_outputs.append( Dense(units=10,activation='relu')(x) )\n",
    "\n",
    "# merge the branches together\n",
    "final_branch = concatenate(all_branch_outputs)\n",
    "final_branch = Dense(units=1,activation='sigmoid')(final_branch)\n",
    "\n",
    "model = Model(inputs=all_inputs, outputs=final_branch)\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_ints_train + [X_train_num],\n",
    "        y_train, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[123   0]\n",
      " [ 24   0]] 0.836734693878\n"
     ]
    }
   ],
   "source": [
    "yhat = np.round(model.predict(X_ints_test + [X_test_num]))\n",
    "print(mt.confusion_matrix(y_test,yhat),mt.accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide: Adding Crossed Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_columns = [['Age','MaritalStatus'],['Age','Gender'],['Department','MonthlyIncome'],['Department','YearsAtCompany'],['Age','TotalWorkingYears'],\n",
    "                    ['Education', 'JobSatisfaction'],['Age','DistanceFromHome'],['Department','PerformanceRating','MonthlyIncome'],\n",
    "                    ['Education', 'JobSatisfaction','RelationshipSatisfaction'],['Department','OverTime','YearsAtCompany'],\n",
    "                    ['Age','TotalWorkingYears','YearsAtCompany']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('sequence item 0: expected str instance, float found', 'occurred at index 1300')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-29075058b8d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0menc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# create crossed labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mX_crossed_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mX_crossed_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\my_root\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[0;32m   4260\u001b[0m                         \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4261\u001b[0m                         \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4262\u001b[1;33m                         ignore_failures=ignore_failures)\n\u001b[0m\u001b[0;32m   4263\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4264\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\my_root\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[1;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[0;32m   4356\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4357\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4358\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4359\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4360\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-29075058b8d3>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0menc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# create crossed labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mX_crossed_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mX_crossed_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ('sequence item 0: expected str instance, float found', 'occurred at index 1300')"
     ]
    }
   ],
   "source": [
    "# we need to create separate sequential models for each embedding\n",
    "embed_branches = []\n",
    "X_ints_train = []\n",
    "X_ints_test = []\n",
    "all_inputs = []\n",
    "all_branch_outputs = []\n",
    "\n",
    "for cols in cross_columns:\n",
    "    # encode as ints for the embedding\n",
    "    enc = LabelEncoder()\n",
    "    # create crossed labels\n",
    "    X_crossed_train = df_train[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "    X_crossed_test = df_test[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "    \n",
    "    enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "    X_crossed_train = enc.transform(X_crossed_train)\n",
    "    X_crossed_test = enc.transform(X_crossed_test)\n",
    "    X_ints_train.append( X_crossed_train )\n",
    "    X_ints_test.append( X_crossed_test )\n",
    "    \n",
    "    # get the number of categories\n",
    "    N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "    \n",
    "    # create embedding branch from the number of categories\n",
    "    inputs = Input(shape=(1,),dtype='int32')\n",
    "    all_inputs.append(inputs)\n",
    "    x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "    x = Flatten()(x)\n",
    "    all_branch_outputs.append(x)\n",
    "    \n",
    "# merge the branches together\n",
    "final_branch = concatenate(all_branch_outputs)\n",
    "final_branch = Dense(units=1,activation='sigmoid')(final_branch)\n",
    "\n",
    "model = Model(inputs=all_inputs, outputs=final_branch)\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_ints_train,\n",
    "        y_train, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
