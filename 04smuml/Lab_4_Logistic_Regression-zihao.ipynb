{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab 4: Extending Logistic Regression\n",
    "\n",
    "Cameron Matson\n",
    "\n",
    "Zihao Mao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Player</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>collage</th>\n",
       "      <th>born</th>\n",
       "      <th>birth_city</th>\n",
       "      <th>birth_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Curly Armstrong</td>\n",
       "      <td>180.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Indiana University</td>\n",
       "      <td>1918.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cliff Barker</td>\n",
       "      <td>188.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>University of Kentucky</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>Yorktown</td>\n",
       "      <td>Indiana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Leo Barnhorst</td>\n",
       "      <td>193.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>University of Notre Dame</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ed Bartels</td>\n",
       "      <td>196.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>North Carolina State University</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Ralph Beard</td>\n",
       "      <td>178.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>University of Kentucky</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>Hardinsburg</td>\n",
       "      <td>Kentucky</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           Player  height  weight  \\\n",
       "0           0  Curly Armstrong   180.0    77.0   \n",
       "1           1     Cliff Barker   188.0    83.0   \n",
       "2           2    Leo Barnhorst   193.0    86.0   \n",
       "3           3       Ed Bartels   196.0    88.0   \n",
       "4           4      Ralph Beard   178.0    79.0   \n",
       "\n",
       "                           collage    born   birth_city birth_state  \n",
       "0               Indiana University  1918.0          NaN         NaN  \n",
       "1           University of Kentucky  1921.0     Yorktown     Indiana  \n",
       "2         University of Notre Dame  1924.0          NaN         NaN  \n",
       "3  North Carolina State University  1925.0          NaN         NaN  \n",
       "4           University of Kentucky  1927.0  Hardinsburg    Kentucky  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first lests load the datasets in\n",
    "\n",
    "data_path = '../data/basketball'\n",
    "players = pd.read_csv(os.path.join(data_path, 'Players.csv'))\n",
    "players.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We probably don't need the \"collage [sic]\" or the their birth locationg.  Probably don't really need their birth year either, but it might be interesting to look at generational splits.  Also that unnamed column looks just like the index, so we can drop that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3922 entries, 0 to 3921\n",
      "Data columns (total 4 columns):\n",
      "Player    3921 non-null object\n",
      "height    3921 non-null float64\n",
      "weight    3921 non-null float64\n",
      "born      3921 non-null float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 122.6+ KB\n"
     ]
    }
   ],
   "source": [
    "players.drop(['Unnamed: 0', 'collage', 'birth_city', 'birth_state'], axis=1, inplace=True)\n",
    "players.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good.  They're all non null, and seem to be the correct datatype.\n",
    "\n",
    "Now let's load the players stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24691 entries, 0 to 24690\n",
      "Data columns (total 53 columns):\n",
      "Unnamed: 0    24691 non-null int64\n",
      "Year          24624 non-null float64\n",
      "Player        24624 non-null object\n",
      "Pos           24624 non-null object\n",
      "Age           24616 non-null float64\n",
      "Tm            24624 non-null object\n",
      "G             24624 non-null float64\n",
      "GS            18233 non-null float64\n",
      "MP            24138 non-null float64\n",
      "PER           24101 non-null float64\n",
      "TS%           24538 non-null float64\n",
      "3PAr          18839 non-null float64\n",
      "FTr           24525 non-null float64\n",
      "ORB%          20792 non-null float64\n",
      "DRB%          20792 non-null float64\n",
      "TRB%          21571 non-null float64\n",
      "AST%          22555 non-null float64\n",
      "STL%          20792 non-null float64\n",
      "BLK%          20792 non-null float64\n",
      "TOV%          19582 non-null float64\n",
      "USG%          19640 non-null float64\n",
      "blanl         0 non-null float64\n",
      "OWS           24585 non-null float64\n",
      "DWS           24585 non-null float64\n",
      "WS            24585 non-null float64\n",
      "WS/48         24101 non-null float64\n",
      "blank2        0 non-null float64\n",
      "OBPM          20797 non-null float64\n",
      "DBPM          20797 non-null float64\n",
      "BPM           20797 non-null float64\n",
      "VORP          20797 non-null float64\n",
      "FG            24624 non-null float64\n",
      "FGA           24624 non-null float64\n",
      "FG%           24525 non-null float64\n",
      "3P            18927 non-null float64\n",
      "3PA           18927 non-null float64\n",
      "3P%           15416 non-null float64\n",
      "2P            24624 non-null float64\n",
      "2PA           24624 non-null float64\n",
      "2P%           24496 non-null float64\n",
      "eFG%          24525 non-null float64\n",
      "FT            24624 non-null float64\n",
      "FTA           24624 non-null float64\n",
      "FT%           23766 non-null float64\n",
      "ORB           20797 non-null float64\n",
      "DRB           20797 non-null float64\n",
      "TRB           24312 non-null float64\n",
      "AST           24624 non-null float64\n",
      "STL           20797 non-null float64\n",
      "BLK           20797 non-null float64\n",
      "TOV           19645 non-null float64\n",
      "PF            24624 non-null float64\n",
      "PTS           24624 non-null float64\n",
      "dtypes: float64(49), int64(1), object(3)\n",
      "memory usage: 10.0+ MB\n"
     ]
    }
   ],
   "source": [
    "stats = pd.read_csv(os.path.join(data_path, 'seasons_stats.csv'))\n",
    "stats.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of fields here, and they're pretty inconsistently filled.  Some of this arises from the fact that its such a long timeline.  For example, in 1950, there was no such thing as a 3-pointer, so it wouldn't make sense for those players to have 3pt% stats. \n",
    "\n",
    "Inspecting the dataset a little further, we notice that there is no stat for points per game (PPG).  The total number of points scored is listed, but that is hard to compare across seasons where they played different games.  To make the dataset more valid, i.e. to make the points column a valid comparisson measure, we'll only consider seasons in which they played the current full 82 game schedule.  Which doesn't reduce the power of the dataset by that much, they moved to a 82 game season in 1967, and only the lockout shortened 1998-99 season didn't have a full scehdule.\n",
    "\n",
    "Actually we might want to limit it to just seasons after 1980 when they introduced the 3 pointer.  That should just make the prediction task easier, although we lose even more of the dataset.  But if we consider the business case as being how to decide players posisitions *TODAY* it makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18380 entries, 5727 to 24690\n",
      "Data columns (total 53 columns):\n",
      "Unnamed: 0    18380 non-null int64\n",
      "Year          18380 non-null float64\n",
      "Player        18380 non-null object\n",
      "Pos           18380 non-null object\n",
      "Age           18380 non-null float64\n",
      "Tm            18380 non-null object\n",
      "G             18380 non-null float64\n",
      "GS            17686 non-null float64\n",
      "MP            18380 non-null float64\n",
      "PER           18375 non-null float64\n",
      "TS%           18307 non-null float64\n",
      "3PAr          18295 non-null float64\n",
      "FTr           18295 non-null float64\n",
      "ORB%          18375 non-null float64\n",
      "DRB%          18375 non-null float64\n",
      "TRB%          18375 non-null float64\n",
      "AST%          18375 non-null float64\n",
      "STL%          18375 non-null float64\n",
      "BLK%          18375 non-null float64\n",
      "TOV%          18321 non-null float64\n",
      "USG%          18375 non-null float64\n",
      "blanl         0 non-null float64\n",
      "OWS           18380 non-null float64\n",
      "DWS           18380 non-null float64\n",
      "WS            18380 non-null float64\n",
      "WS/48         18375 non-null float64\n",
      "blank2        0 non-null float64\n",
      "OBPM          18380 non-null float64\n",
      "DBPM          18380 non-null float64\n",
      "BPM           18380 non-null float64\n",
      "VORP          18380 non-null float64\n",
      "FG            18380 non-null float64\n",
      "FGA           18380 non-null float64\n",
      "FG%           18295 non-null float64\n",
      "3P            18380 non-null float64\n",
      "3PA           18380 non-null float64\n",
      "3P%           14969 non-null float64\n",
      "2P            18380 non-null float64\n",
      "2PA           18380 non-null float64\n",
      "2P%           18266 non-null float64\n",
      "eFG%          18295 non-null float64\n",
      "FT            18380 non-null float64\n",
      "FTA           18380 non-null float64\n",
      "FT%           17657 non-null float64\n",
      "ORB           18380 non-null float64\n",
      "DRB           18380 non-null float64\n",
      "TRB           18380 non-null float64\n",
      "AST           18380 non-null float64\n",
      "STL           18380 non-null float64\n",
      "BLK           18380 non-null float64\n",
      "TOV           18380 non-null float64\n",
      "PF            18380 non-null float64\n",
      "PTS           18380 non-null float64\n",
      "dtypes: float64(49), int64(1), object(3)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "stats = stats[stats.Year >= 1980]\n",
    "stats = stats[stats.Year != 1998]\n",
    "stats.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets just focus on a few categories\n",
    "- Player\n",
    "- Year\n",
    "- Age\n",
    "- games played (G)\n",
    "- minutes played (MP)\n",
    "- field goals, field goal attempts, and percentage (FG, FGA, FG%)\n",
    "- free throws (FT, FTA, FT%), two-pointers (2P, 2PA, 2P%), and three-pointers (3P, 3PA, 3P%)\n",
    "- offensive, defensive, and total rebounds (ORB, DRB, TRB)\n",
    "- assists (AST)\n",
    "- steals (STL)\n",
    "- blocks (BLK)\n",
    "- turnovers (TOV)\n",
    "- personal fouls (PF)\n",
    "- points (PTS)\n",
    "\n",
    "And of course our label: position.  We could probably use any of the features as a label actually, and see if one could predict performance in one aspect of the game based on info in the another.  But for now we'll stick with predicting position.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18380 entries, 5727 to 24690\n",
      "Data columns (total 27 columns):\n",
      "Year      18380 non-null float64\n",
      "Player    18380 non-null object\n",
      "Pos       18380 non-null object\n",
      "Age       18380 non-null float64\n",
      "G         18380 non-null float64\n",
      "MP        18380 non-null float64\n",
      "FG        18380 non-null float64\n",
      "FGA       18380 non-null float64\n",
      "FG%       18295 non-null float64\n",
      "3P        18380 non-null float64\n",
      "3PA       18380 non-null float64\n",
      "3P%       14969 non-null float64\n",
      "2P        18380 non-null float64\n",
      "2PA       18380 non-null float64\n",
      "2P%       18266 non-null float64\n",
      "FT        18380 non-null float64\n",
      "FTA       18380 non-null float64\n",
      "FT%       17657 non-null float64\n",
      "ORB       18380 non-null float64\n",
      "DRB       18380 non-null float64\n",
      "TRB       18380 non-null float64\n",
      "AST       18380 non-null float64\n",
      "STL       18380 non-null float64\n",
      "BLK       18380 non-null float64\n",
      "TOV       18380 non-null float64\n",
      "PF        18380 non-null float64\n",
      "PTS       18380 non-null float64\n",
      "dtypes: float64(25), object(2)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "stats_to_keep = {'Player', 'Year','Pos', 'Age', 'G', 'MP', 'FG', 'FGA', 'FG%', 'FT', 'FTA', 'FT%',\n",
    "                '2P', '2PA', '2P%', '3P', '3PA', '3P%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK',\n",
    "                'TOV', 'PF', 'PTS'}\n",
    "\n",
    "stats_to_drop = set(stats.columns)-stats_to_keep\n",
    "stats.drop(stats_to_drop, axis=1, inplace=True)\n",
    "stats.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take care of some of the null values, when players had 0 attempts in a shooting category (FG, 3P, 2P, FT) they left the percentage field blank (can't divide by 0), but for our purposes its probably okay if we just say it was 0%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats['3P%'] = stats['3P%'].fillna(0)\n",
    "stats['2P%'] = stats['2P%'].fillna(0)\n",
    "stats['FT%'] = stats['FT%'].fillna(0)\n",
    "stats['FG%'] = stats['FG%'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay.  Finally, let's add the player description data to the stats dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats['height'] = np.nan\n",
    "stats['weight'] = np.nan\n",
    "stats['born'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iplayer = players.set_index(keys='Player')\n",
    "istats = stats.reset_index(drop=True)\n",
    "for i, row in istats.iterrows():\n",
    "    name = row[1]\n",
    "    h = iplayer.loc[name].loc['height']\n",
    "    w = iplayer.loc[name].loc['weight']\n",
    "    b = iplayer.loc[name].loc['born']\n",
    "    istats.iloc[i, 27] = h\n",
    "    istats.iloc[i, 28] = w\n",
    "    istats.iloc[i, 29] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18380 entries, 0 to 18379\n",
      "Data columns (total 30 columns):\n",
      "Year      18380 non-null float64\n",
      "Player    18380 non-null object\n",
      "Pos       18380 non-null object\n",
      "Age       18380 non-null float64\n",
      "G         18380 non-null float64\n",
      "MP        18380 non-null float64\n",
      "FG        18380 non-null float64\n",
      "FGA       18380 non-null float64\n",
      "FG%       18380 non-null float64\n",
      "3P        18380 non-null float64\n",
      "3PA       18380 non-null float64\n",
      "3P%       18380 non-null float64\n",
      "2P        18380 non-null float64\n",
      "2PA       18380 non-null float64\n",
      "2P%       18380 non-null float64\n",
      "FT        18380 non-null float64\n",
      "FTA       18380 non-null float64\n",
      "FT%       18380 non-null float64\n",
      "ORB       18380 non-null float64\n",
      "DRB       18380 non-null float64\n",
      "TRB       18380 non-null float64\n",
      "AST       18380 non-null float64\n",
      "STL       18380 non-null float64\n",
      "BLK       18380 non-null float64\n",
      "TOV       18380 non-null float64\n",
      "PF        18380 non-null float64\n",
      "PTS       18380 non-null float64\n",
      "height    18380 non-null float64\n",
      "weight    18380 non-null float64\n",
      "born      18380 non-null float64\n",
      "dtypes: float64(28), object(2)\n",
      "memory usage: 4.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>G</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>...</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>born</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980.0</td>\n",
       "      <td>Kareem Abdul-Jabbar*</td>\n",
       "      <td>C</td>\n",
       "      <td>32.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>3143.0</td>\n",
       "      <td>835.0</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>886.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>2034.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1947.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980.0</td>\n",
       "      <td>Tom Abernethy</td>\n",
       "      <td>PF</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>191.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1954.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980.0</td>\n",
       "      <td>Alvan Adams</td>\n",
       "      <td>C</td>\n",
       "      <td>25.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2168.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>875.0</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>609.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1954.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980.0</td>\n",
       "      <td>Tiny Archibald*</td>\n",
       "      <td>PG</td>\n",
       "      <td>31.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2864.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>794.0</td>\n",
       "      <td>0.482</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>197.0</td>\n",
       "      <td>671.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>1131.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980.0</td>\n",
       "      <td>Dennis Awtrey</td>\n",
       "      <td>C</td>\n",
       "      <td>31.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>115.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1948.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year                Player Pos   Age     G      MP     FG     FGA    FG%  \\\n",
       "0  1980.0  Kareem Abdul-Jabbar*   C  32.0  82.0  3143.0  835.0  1383.0  0.604   \n",
       "1  1980.0         Tom Abernethy  PF  25.0  67.0  1222.0  153.0   318.0  0.481   \n",
       "2  1980.0           Alvan Adams   C  25.0  75.0  2168.0  465.0   875.0  0.531   \n",
       "3  1980.0       Tiny Archibald*  PG  31.0  80.0  2864.0  383.0   794.0  0.482   \n",
       "4  1980.0         Dennis Awtrey   C  31.0  26.0   560.0   27.0    60.0  0.450   \n",
       "\n",
       "    3P   ...      TRB    AST    STL    BLK    TOV     PF     PTS  height  \\\n",
       "0  0.0   ...    886.0  371.0   81.0  280.0  297.0  216.0  2034.0   218.0   \n",
       "1  0.0   ...    191.0   87.0   35.0   12.0   39.0  118.0   362.0   201.0   \n",
       "2  0.0   ...    609.0  322.0  108.0   55.0  218.0  237.0  1118.0   206.0   \n",
       "3  4.0   ...    197.0  671.0  106.0   10.0  242.0  218.0  1131.0   185.0   \n",
       "4  0.0   ...    115.0   40.0   12.0   15.0   27.0   66.0    86.0   208.0   \n",
       "\n",
       "   weight    born  \n",
       "0   102.0  1947.0  \n",
       "1    99.0  1954.0  \n",
       "2    95.0  1954.0  \n",
       "3    68.0  1948.0  \n",
       "4   106.0  1948.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = istats\n",
    "stats.info()\n",
    "stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18380 entries, 0 to 18379\n",
      "Data columns (total 27 columns):\n",
      "Pos       18380 non-null object\n",
      "Age       18380 non-null float64\n",
      "G         18380 non-null float64\n",
      "MP        18380 non-null float64\n",
      "FG        18380 non-null float64\n",
      "FGA       18380 non-null float64\n",
      "FG%       18380 non-null float64\n",
      "3P        18380 non-null float64\n",
      "3PA       18380 non-null float64\n",
      "3P%       18380 non-null float64\n",
      "2P        18380 non-null float64\n",
      "2PA       18380 non-null float64\n",
      "2P%       18380 non-null float64\n",
      "FT        18380 non-null float64\n",
      "FTA       18380 non-null float64\n",
      "FT%       18380 non-null float64\n",
      "ORB       18380 non-null float64\n",
      "DRB       18380 non-null float64\n",
      "TRB       18380 non-null float64\n",
      "AST       18380 non-null float64\n",
      "STL       18380 non-null float64\n",
      "BLK       18380 non-null float64\n",
      "TOV       18380 non-null float64\n",
      "PF        18380 non-null float64\n",
      "PTS       18380 non-null float64\n",
      "height    18380 non-null float64\n",
      "weight    18380 non-null float64\n",
      "dtypes: float64(26), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "stats.drop(['Year','Player','born'], axis=1, inplace=True)\n",
    "positions = stats['Pos'] # restore the position data for testing classifications\n",
    "stat = stats\n",
    "stat.info()\n",
    "stat.drop(['Pos'], axis=1, inplace=True) #remove the position feature from the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18380 entries, 0 to 18379\n",
      "Data columns (total 26 columns):\n",
      "Age       18380 non-null float64\n",
      "G         18380 non-null float64\n",
      "MP        18380 non-null float64\n",
      "FG        18380 non-null float64\n",
      "FGA       18380 non-null float64\n",
      "FG%       18380 non-null float64\n",
      "3P        18380 non-null float64\n",
      "3PA       18380 non-null float64\n",
      "3P%       18380 non-null float64\n",
      "2P        18380 non-null float64\n",
      "2PA       18380 non-null float64\n",
      "2P%       18380 non-null float64\n",
      "FT        18380 non-null float64\n",
      "FTA       18380 non-null float64\n",
      "FT%       18380 non-null float64\n",
      "ORB       18380 non-null float64\n",
      "DRB       18380 non-null float64\n",
      "TRB       18380 non-null float64\n",
      "AST       18380 non-null float64\n",
      "STL       18380 non-null float64\n",
      "BLK       18380 non-null float64\n",
      "TOV       18380 non-null float64\n",
      "PF        18380 non-null float64\n",
      "PTS       18380 non-null float64\n",
      "height    18380 non-null float64\n",
      "weight    18380 non-null float64\n",
      "dtypes: float64(26)\n",
      "memory usage: 3.6 MB\n"
     ]
    }
   ],
   "source": [
    "#normalize the numeric datas\n",
    "from sklearn import preprocessing\n",
    "X = stat.values\n",
    "y = stat.columns\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X)\n",
    "stat = pd.DataFrame(x_scaled, columns = y)\n",
    "stat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PCA\n",
    "\n",
    "Use PCA to reduce the demension of the data to 2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the top 2 eigenfaces from 26 faces\n",
      "Wall time: 0 ns\n",
      "pca: [[ 0.00340159  0.44303303  0.40148528  0.24562555  0.24652775  0.0575184\n",
      "   0.06574366  0.08350179  0.06568503  0.22400359  0.22044924  0.05694294\n",
      "   0.17577517  0.19441659  0.12215646  0.13198765  0.18670172  0.17231213\n",
      "   0.13069441  0.16437958  0.06911151  0.20788636  0.29651674  0.23421354\n",
      "   0.00400838  0.00074279]\n",
      " [-0.0575088  -0.03130873 -0.03561589 -0.01079286 -0.05525003  0.07681439\n",
      "  -0.20787281 -0.2522501  -0.52164214  0.06603528  0.04409344  0.04931209\n",
      "   0.01162407  0.05261553 -0.3721118   0.22906628  0.18580128  0.20807638\n",
      "  -0.15856858 -0.09161807  0.1527345  -0.01743282  0.16505092 -0.03208916\n",
      "   0.37121133  0.32060454]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "n_components = 2\n",
    "print (\"Extracting the top %d eigenfaces from %d faces\" % (\n",
    "    n_components, stats.shape[1]))\n",
    "pca = PCA(n_components=n_components)\n",
    "%time \n",
    "stat_pca = pca.fit(stat.copy()).transform(stat.copy())\n",
    "\n",
    "print ('pca:', pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = pd.DataFrame(stat_pca, columns = ['first', 'second'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.625438</td>\n",
       "      <td>0.553955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013658</td>\n",
       "      <td>0.153532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.923291</td>\n",
       "      <td>0.292951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.966552</td>\n",
       "      <td>-0.279464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.512837</td>\n",
       "      <td>0.189599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      first    second\n",
       "0  1.625438  0.553955\n",
       "1  0.013658  0.153532\n",
       "2  0.923291  0.292951\n",
       "3  0.966552 -0.279464\n",
       "4 -0.512837  0.189599"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logic Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BinaryLogisticRegressionBase:\n",
    "    # private:\n",
    "    def __init__(self, eta, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Base Binary Logistic Regression Object, Not Trainable'\n",
    "    \n",
    "    # convenience, private:\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        return 1/(1+np.exp(-theta)) \n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    \n",
    "    # public:\n",
    "    def predict_proba(self,X,add_bias=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_bias(X) if add_bias else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5) #return the actual prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained Binary Logistic Regression Object\n"
     ]
    }
   ],
   "source": [
    "# inherit from base class\n",
    "class BinaryLogisticRegression(BinaryLogisticRegressionBase):\n",
    "    #private:\n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'Binary Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained Binary Logistic Regression Object'\n",
    "        \n",
    "    def _get_gradient(self,X,y):\n",
    "        # programming \\sum_i (yi-g(xi))xi\n",
    "        gradient = np.zeros(self.w_.shape) # set gradient to zero\n",
    "        for (xi,yi) in zip(X,y):\n",
    "            # the actual update inside of sum\n",
    "            gradi = (yi - self.predict_proba(xi,add_bias=False))*xi \n",
    "            # reshape to be column vector and add to gradient\n",
    "            gradient += gradi.reshape(self.w_.shape) \n",
    "        \n",
    "        return gradient/float(len(y))\n",
    "       \n",
    "    # public:\n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            self.w_ += gradient*self.eta # multiply by learning rate \n",
    "\n",
    "            \n",
    "blr = BinaryLogisticRegression(0.1)\n",
    "print(blr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "import copy\n",
    "class LineSearchLogisticRegression(BinaryLogisticRegression):\n",
    "    \n",
    "    # define custom line search for problem\n",
    "    @staticmethod\n",
    "    def line_search_function(eta,X,y,w,grad,C):\n",
    "        wnew = w + grad*eta\n",
    "        yhat = (1/(1+np.exp(-X @ wnew)))>0.5\n",
    "        return np.sum((y-yhat)**2)-C*np.sum(wnew**2)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            \n",
    "            # do line search in gradient direction, using scipy function\n",
    "            opts = {'maxiter':self.iters/20} # unclear exactly what this should be\n",
    "            res = minimize_scalar(self.line_search_function, # objective function to optimize\n",
    "                                  bounds=(self.eta/1000,self.eta*10), #bounds to optimize\n",
    "                                  args=(Xb,y,self.w_,gradient,self.C), # additional argument for objective function\n",
    "                                  method='bounded', # bounded optimization for speed\n",
    "                                  options=opts) # set max iterations\n",
    "            \n",
    "            eta = res.x # get optimal learning rate\n",
    "            self.w_ += gradient*eta # set new function values\n",
    "                \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "class VectorBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    # inherit from our previous class to get same functionality\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # but overwrite the gradient calculation\n",
    "    def _get_gradient(self,X,y):\n",
    "        ydiff = y-self.predict_proba(X,add_bias=False).ravel() # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        \n",
    "        return gradient.reshape(self.w_.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, eta, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained MultiClass Logistic Regression Object'\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.unique(y) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = [] # will fill this array with binary classifiers\n",
    "        \n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = y==yval # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            blr = VectorBinaryLogisticRegression(self.eta,self.iters)\n",
    "            blr.fit(X,y_binary)\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(blr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        probs = []\n",
    "        for blr in self.classifiers_:\n",
    "            probs.append(blr.predict_proba(X)) # get probability for each classifier\n",
    "        \n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return np.argmax(self.predict_proba(X),axis=1) # take argmax along row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RegularizedBinaryLogisticRegression(VectorBinaryLogisticRegression):\n",
    "    # extend init functions\n",
    "    def __init__(self, C=0.0, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.C = C\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds) # call parent initializer\n",
    "        \n",
    "        \n",
    "    # extend previous class to change functionality\n",
    "    def _get_gradient(self,X,y):\n",
    "        # call get gradient from previous class\n",
    "        gradient = super()._get_gradient(X,y)\n",
    "        \n",
    "        # add in regularization (to all except bias term)\n",
    "        gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        return gradient\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now redefine the Logistic Regression Function where needed\n",
    "class RegularizedLogisticRegression(LogisticRegression):\n",
    "    def __init__(self, C=0.0, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.C = C\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds) # call parent initializer\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.unique(y) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = [] # will fill this array with binary classifiers\n",
    "        \n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = y==yval # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            blr = RegularizedBinaryLogisticRegression(eta=self.eta,\n",
    "                                                      iterations=self.iters,\n",
    "                                                      C=self.C)\n",
    "            blr.fit(X,y_binary)\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(blr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data for test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "if 'Pos' in stat:\n",
    "    positions = df_imputed['Survived'].values \n",
    "    del df_imputed['Survived'] \n",
    "    norm_features = ['Age','Fare' ]\n",
    "    df_imputed[norm_features] = (df_imputed[norm_features]-df_imputed[norm_features].mean()) / df_imputed[norm_features].std()\n",
    "    X = df_imputed.values \n",
    "\n",
    "\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(positions)\n",
    "cv_object = ShuffleSplit(\n",
    "                         n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-ba0ca3630f7a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-24-ba0ca3630f7a>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    X =\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "X = \n",
    "print(positions.shape)\n",
    "print(stat.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%time\n",
    "lr = LogisticRegression(0.1,500)\n",
    "lr.fit(X,y)\n",
    "\n",
    "yhat = lr.predict(X)\n",
    "print('Accuracy of: ',accuracy_score(y,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_num=0\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "\n",
    "    \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
