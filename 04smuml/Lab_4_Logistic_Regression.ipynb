{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab 4: Extending Logistic Regression\n",
    "\n",
    "Cameron Matson\n",
    "\n",
    "Zihao Mao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Player</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>collage</th>\n",
       "      <th>born</th>\n",
       "      <th>birth_city</th>\n",
       "      <th>birth_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Curly Armstrong</td>\n",
       "      <td>180.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Indiana University</td>\n",
       "      <td>1918.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cliff Barker</td>\n",
       "      <td>188.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>University of Kentucky</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>Yorktown</td>\n",
       "      <td>Indiana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Leo Barnhorst</td>\n",
       "      <td>193.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>University of Notre Dame</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ed Bartels</td>\n",
       "      <td>196.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>North Carolina State University</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Ralph Beard</td>\n",
       "      <td>178.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>University of Kentucky</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>Hardinsburg</td>\n",
       "      <td>Kentucky</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           Player  height  weight  \\\n",
       "0           0  Curly Armstrong   180.0    77.0   \n",
       "1           1     Cliff Barker   188.0    83.0   \n",
       "2           2    Leo Barnhorst   193.0    86.0   \n",
       "3           3       Ed Bartels   196.0    88.0   \n",
       "4           4      Ralph Beard   178.0    79.0   \n",
       "\n",
       "                           collage    born   birth_city birth_state  \n",
       "0               Indiana University  1918.0          NaN         NaN  \n",
       "1           University of Kentucky  1921.0     Yorktown     Indiana  \n",
       "2         University of Notre Dame  1924.0          NaN         NaN  \n",
       "3  North Carolina State University  1925.0          NaN         NaN  \n",
       "4           University of Kentucky  1927.0  Hardinsburg    Kentucky  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first lests load the datasets in\n",
    "\n",
    "data_path = '../../data/nba-players-stats-since-1950'\n",
    "players = pd.read_csv(os.path.join(data_path, 'players.csv'))\n",
    "players.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We probably don't need the \"collage [sic]\" or the their birth locationg.  Probably don't really need their birth year either, but it might be interesting to look at generational splits.  Also that unnamed column looks just like the index, so we can drop that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3922 entries, 0 to 3921\n",
      "Data columns (total 3 columns):\n",
      "Player    3921 non-null object\n",
      "height    3921 non-null float64\n",
      "weight    3921 non-null float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 92.0+ KB\n"
     ]
    }
   ],
   "source": [
    "players.drop(['Unnamed: 0', 'collage', 'birth_city', 'birth_state', 'born'], axis=1, inplace=True)\n",
    "players.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good.  They're all non null, and seem to be the correct datatype.\n",
    "\n",
    "Now let's load the players stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24691 entries, 0 to 24690\n",
      "Data columns (total 53 columns):\n",
      "Unnamed: 0    24691 non-null int64\n",
      "Year          24624 non-null float64\n",
      "Player        24624 non-null object\n",
      "Pos           24624 non-null object\n",
      "Age           24616 non-null float64\n",
      "Tm            24624 non-null object\n",
      "G             24624 non-null float64\n",
      "GS            18233 non-null float64\n",
      "MP            24138 non-null float64\n",
      "PER           24101 non-null float64\n",
      "TS%           24538 non-null float64\n",
      "3PAr          18839 non-null float64\n",
      "FTr           24525 non-null float64\n",
      "ORB%          20792 non-null float64\n",
      "DRB%          20792 non-null float64\n",
      "TRB%          21571 non-null float64\n",
      "AST%          22555 non-null float64\n",
      "STL%          20792 non-null float64\n",
      "BLK%          20792 non-null float64\n",
      "TOV%          19582 non-null float64\n",
      "USG%          19640 non-null float64\n",
      "blanl         0 non-null float64\n",
      "OWS           24585 non-null float64\n",
      "DWS           24585 non-null float64\n",
      "WS            24585 non-null float64\n",
      "WS/48         24101 non-null float64\n",
      "blank2        0 non-null float64\n",
      "OBPM          20797 non-null float64\n",
      "DBPM          20797 non-null float64\n",
      "BPM           20797 non-null float64\n",
      "VORP          20797 non-null float64\n",
      "FG            24624 non-null float64\n",
      "FGA           24624 non-null float64\n",
      "FG%           24525 non-null float64\n",
      "3P            18927 non-null float64\n",
      "3PA           18927 non-null float64\n",
      "3P%           15416 non-null float64\n",
      "2P            24624 non-null float64\n",
      "2PA           24624 non-null float64\n",
      "2P%           24496 non-null float64\n",
      "eFG%          24525 non-null float64\n",
      "FT            24624 non-null float64\n",
      "FTA           24624 non-null float64\n",
      "FT%           23766 non-null float64\n",
      "ORB           20797 non-null float64\n",
      "DRB           20797 non-null float64\n",
      "TRB           24312 non-null float64\n",
      "AST           24624 non-null float64\n",
      "STL           20797 non-null float64\n",
      "BLK           20797 non-null float64\n",
      "TOV           19645 non-null float64\n",
      "PF            24624 non-null float64\n",
      "PTS           24624 non-null float64\n",
      "dtypes: float64(49), int64(1), object(3)\n",
      "memory usage: 10.0+ MB\n"
     ]
    }
   ],
   "source": [
    "stats = pd.read_csv(os.path.join(data_path, 'seasons_stats.csv'))\n",
    "stats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of fields here, and they're pretty inconsistently filled.  Some of this arises from the fact that its such a long timeline.  For example, in 1950, there was no such thing as a 3-pointer, so it wouldn't make sense for those players to have 3pt% stats. \n",
    "\n",
    "Inspecting the dataset a little further, we notice that there is no stat for points per game (PPG).  The total number of points scored is listed, but that is hard to compare across seasons where they played different games.  To make the dataset more valid, i.e. to make the points column a valid comparisson measure, we'll only consider seasons in which they played the current full 82 game schedule.  Which doesn't reduce the power of the dataset by that much, they moved to a 82 game season in 1967, and only the lockout shortened 1998-99 season didn't have a full scehdule.\n",
    "\n",
    "Actually we might want to limit it to just seasons after 1980 when they introduced the 3 pointer.  That should just make the prediction task easier, although we lose even more of the dataset.  But if we consider the business case as being how to decide players posisitions *TODAY* it makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18380 entries, 5727 to 24690\n",
      "Data columns (total 53 columns):\n",
      "Unnamed: 0    18380 non-null int64\n",
      "Year          18380 non-null float64\n",
      "Player        18380 non-null object\n",
      "Pos           18380 non-null object\n",
      "Age           18380 non-null float64\n",
      "Tm            18380 non-null object\n",
      "G             18380 non-null float64\n",
      "GS            17686 non-null float64\n",
      "MP            18380 non-null float64\n",
      "PER           18375 non-null float64\n",
      "TS%           18307 non-null float64\n",
      "3PAr          18295 non-null float64\n",
      "FTr           18295 non-null float64\n",
      "ORB%          18375 non-null float64\n",
      "DRB%          18375 non-null float64\n",
      "TRB%          18375 non-null float64\n",
      "AST%          18375 non-null float64\n",
      "STL%          18375 non-null float64\n",
      "BLK%          18375 non-null float64\n",
      "TOV%          18321 non-null float64\n",
      "USG%          18375 non-null float64\n",
      "blanl         0 non-null float64\n",
      "OWS           18380 non-null float64\n",
      "DWS           18380 non-null float64\n",
      "WS            18380 non-null float64\n",
      "WS/48         18375 non-null float64\n",
      "blank2        0 non-null float64\n",
      "OBPM          18380 non-null float64\n",
      "DBPM          18380 non-null float64\n",
      "BPM           18380 non-null float64\n",
      "VORP          18380 non-null float64\n",
      "FG            18380 non-null float64\n",
      "FGA           18380 non-null float64\n",
      "FG%           18295 non-null float64\n",
      "3P            18380 non-null float64\n",
      "3PA           18380 non-null float64\n",
      "3P%           14969 non-null float64\n",
      "2P            18380 non-null float64\n",
      "2PA           18380 non-null float64\n",
      "2P%           18266 non-null float64\n",
      "eFG%          18295 non-null float64\n",
      "FT            18380 non-null float64\n",
      "FTA           18380 non-null float64\n",
      "FT%           17657 non-null float64\n",
      "ORB           18380 non-null float64\n",
      "DRB           18380 non-null float64\n",
      "TRB           18380 non-null float64\n",
      "AST           18380 non-null float64\n",
      "STL           18380 non-null float64\n",
      "BLK           18380 non-null float64\n",
      "TOV           18380 non-null float64\n",
      "PF            18380 non-null float64\n",
      "PTS           18380 non-null float64\n",
      "dtypes: float64(49), int64(1), object(3)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "stats = stats[stats.Year >= 1980]\n",
    "stats = stats[stats.Year != 1998]\n",
    "stats.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets just focus on a few categories\n",
    "- Player\n",
    "- Year\n",
    "- Age\n",
    "- games played (G)\n",
    "- minutes played (MP)\n",
    "- field goals, feild goal attempts, and percentage (FG, FGA, FG%)\n",
    "- free throws (FT, FTA, FT%), two-pointers (2P, 2PA, 2P%), and three-pointers (3P, 3PA, 3P%)\n",
    "- offensive, defensive, and total rebounds (ORB, DRB, TRB)\n",
    "- assists (AST)\n",
    "- steals (STL)\n",
    "- blocks (BLK)\n",
    "- turnovers (TOV)\n",
    "- personal fouls (PF)\n",
    "- points (PTS)\n",
    "\n",
    "And of course our label: position.  We could probably use any of the features as a label actually, and see if one could predict performance in one aspect of the game based on info in the another.  But for now we'll stick with predicting position.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18380 entries, 5727 to 24690\n",
      "Data columns (total 27 columns):\n",
      "Year      18380 non-null float64\n",
      "Player    18380 non-null object\n",
      "Pos       18380 non-null object\n",
      "Age       18380 non-null float64\n",
      "G         18380 non-null float64\n",
      "MP        18380 non-null float64\n",
      "FG        18380 non-null float64\n",
      "FGA       18380 non-null float64\n",
      "FG%       18295 non-null float64\n",
      "3P        18380 non-null float64\n",
      "3PA       18380 non-null float64\n",
      "3P%       14969 non-null float64\n",
      "2P        18380 non-null float64\n",
      "2PA       18380 non-null float64\n",
      "2P%       18266 non-null float64\n",
      "FT        18380 non-null float64\n",
      "FTA       18380 non-null float64\n",
      "FT%       17657 non-null float64\n",
      "ORB       18380 non-null float64\n",
      "DRB       18380 non-null float64\n",
      "TRB       18380 non-null float64\n",
      "AST       18380 non-null float64\n",
      "STL       18380 non-null float64\n",
      "BLK       18380 non-null float64\n",
      "TOV       18380 non-null float64\n",
      "PF        18380 non-null float64\n",
      "PTS       18380 non-null float64\n",
      "dtypes: float64(25), object(2)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "stats_to_keep = {'Player', 'Year','Pos', 'Age', 'G', 'MP', 'FG', 'FGA', 'FG%', 'FT', 'FTA', 'FT%',\n",
    "                '2P', '2PA', '2P%', '3P', '3PA', '3P%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK',\n",
    "                'TOV', 'PF', 'PTS'}\n",
    "\n",
    "stats_to_drop = set(stats.columns)-stats_to_keep\n",
    "stats.drop(stats_to_drop, axis=1, inplace=True)\n",
    "stats.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take care of some of the null values, when players had 0 attempts in a shooting category (FG, 3P, 2P, FT) they left the percentage field blank (can't divide by 0), but for our purposes its probably okay if we just say it was 0%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats['3P%'] = stats['3P%'].fillna(0)\n",
    "stats['2P%'] = stats['2P%'].fillna(0)\n",
    "stats['FT%'] = stats['FT%'].fillna(0)\n",
    "stats['FG%'] = stats['FG%'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay.  Finally, let's add the player description data to the stats dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats['height'] = np.nan\n",
    "stats['weight'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iplayer = players.set_index(keys='Player')\n",
    "istats = stats.reset_index(drop=True)\n",
    "for i, row in istats.iterrows():\n",
    "    name = row[1]\n",
    "    h = iplayer.loc[name].loc['height']\n",
    "    w = iplayer.loc[name].loc['weight']\n",
    "    istats.iloc[i, 27] = h\n",
    "    istats.iloc[i, 28] = w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = istats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# and now we don't need the names anymore\n",
    "stats.drop(['Player', 'Year'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Binary Logistic Regression Object, Not Trainable\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class BinaryLogisticRegressionBase:\n",
    "    # private:\n",
    "    def __init__(self, eta, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Base Binary Logistic Regression Object, Not Trainable'\n",
    "    \n",
    "    # convenience, private:\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        return 1/(1+np.exp(-theta)) \n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "\n",
    "    # public:\n",
    "    def predict_proba(self,X,add_bias=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_bias(X) if add_bias else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5) #return the actual prediction\n",
    "    \n",
    "    \n",
    "        \n",
    "blr = BinaryLogisticRegressionBase(0.1)\n",
    "print(blr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained Binary Logistic Regression Object\n"
     ]
    }
   ],
   "source": [
    "# inherit from base class\n",
    "class BinaryLogisticRegression(BinaryLogisticRegressionBase):\n",
    "    #private:\n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'Binary Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained Binary Logistic Regression Object'\n",
    "        \n",
    "    def _get_gradient(self,X,y):\n",
    "        # programming \\sum_i (yi-g(xi))xi\n",
    "        gradient = np.zeros(self.w_.shape) # set gradient to zero\n",
    "        for (xi,yi) in zip(X,y):\n",
    "            # the actual update inside of sum\n",
    "            gradi = (yi - self.predict_proba(xi,add_bias=False))*xi \n",
    "            # reshape to be column vector and add to gradient\n",
    "            gradient += gradi.reshape(self.w_.shape) \n",
    "        \n",
    "        return gradient/float(len(y))\n",
    "       \n",
    "    # public:\n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            self.w_ += gradient*self.eta # multiply by learning rate \n",
    "\n",
    "            \n",
    "blr = BinaryLogisticRegression(0.1)\n",
    "print(blr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets do some vectorized coding\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "\n",
    "class VectorBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    # inherit from our previous class to get same functionality\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # but overwrite the gradient calculation\n",
    "    def _get_gradient(self,X,y):\n",
    "        yhat = self.predict_proba(X, add_bias=False).ravel()[:, np.newaxis]\n",
    "        ydiff = y-yhat # get y difference\n",
    "\n",
    "        \n",
    "        gradient = np.mean(X * ydiff, axis=0) # make ydiff a column vector and multiply through\n",
    "        \n",
    "        return gradient.reshape(self.w_.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C',\n",
       " 'C-PF',\n",
       " 'C-SF',\n",
       " 'PF',\n",
       " 'PF-C',\n",
       " 'PF-SF',\n",
       " 'PG',\n",
       " 'PG-SF',\n",
       " 'PG-SG',\n",
       " 'SF',\n",
       " 'SF-PF',\n",
       " 'SF-SG',\n",
       " 'SG',\n",
       " 'SG-PF',\n",
       " 'SG-PG',\n",
       " 'SG-SF'}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we need to separate out the label from the data\n",
    "y = stats.Pos\n",
    "set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets reclassify this numerically and only count their 'primary ' position, so that each player will be given a position 1-5\n",
    "# {(1, pg), (2, sg), (3, sf), (4, pf), (5, c)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def convert_pos(y):\n",
    "    newy = np.zeros((len(y), 1))\n",
    "    for i, player in enumerate(y):\n",
    "        if (player[0] == 'C'):\n",
    "            newy[i] = 5\n",
    "        elif (player[0:2] == 'PF'):\n",
    "            newy[i] = 4\n",
    "        elif (player[0:2] == 'SF'):\n",
    "            newy[i] = 3\n",
    "        elif (player[0:2] == 'SG'):\n",
    "            newy[i] = 2\n",
    "        elif (player[0:2] == 'PG'):\n",
    "            newy[i] = 1\n",
    "    return newy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.],\n",
       "       [ 4.],\n",
       "       [ 5.],\n",
       "       ..., \n",
       "       [ 5.],\n",
       "       [ 3.],\n",
       "       [ 5.]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = convert_pos(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18380, 1)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stats.drop('Pos', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.scale(X, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18380, 26)\n",
      "(18380, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18380, 1)\n"
     ]
    }
   ],
   "source": [
    "yb = (y>4).astype(np.int)\n",
    "print(yb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, yb, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.33417179]\n",
      " [-0.29242637]\n",
      " [ 0.05288225]\n",
      " [-0.62882745]\n",
      " [-0.05254612]\n",
      " [-0.98733578]\n",
      " [-0.18516478]\n",
      " [-0.66762493]\n",
      " [-1.72791743]\n",
      " [-0.20139884]\n",
      " [ 0.42976244]\n",
      " [ 0.55526528]\n",
      " [-0.1875345 ]\n",
      " [-0.09727805]\n",
      " [ 0.12954605]\n",
      " [-0.19288822]\n",
      " [ 0.45455409]\n",
      " [ 1.33830389]\n",
      " [ 1.97817434]\n",
      " [-1.62281839]\n",
      " [-0.866978  ]\n",
      " [ 1.44856858]\n",
      " [-0.15530826]\n",
      " [ 1.29662916]\n",
      " [-0.3140461 ]\n",
      " [-0.62939831]\n",
      " [ 1.12580547]]\n",
      "Accuracy of:  0.852829162133\n",
      "Wall time: 3.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Now we can train the classifier\n",
    "params = dict(eta=0.2,\n",
    "              iterations=1000)\n",
    "blr = VectorBinaryLogisticRegression(**params)\n",
    "blr.fit(X_train,y_train)\n",
    "print(blr.w_)\n",
    "yhat = blr.predict(X_test)\n",
    "print('Accuracy of: ',accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained MultiClass Logistic Regression Object\n"
     ]
    }
   ],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, eta, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained MultiClass Logistic Regression Object'\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.unique(y) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = [] # will fill this array with binary classifiers\n",
    "        \n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = y==yval # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            blr = VectorBinaryLogisticRegression(self.eta,self.iters)\n",
    "            blr.fit(X,y_binary)\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(blr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        probs = []\n",
    "        for blr in self.classifiers_:\n",
    "            probs.append(blr.predict_proba(X)) # get probability for each classifier\n",
    "        \n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return np.argmax(self.predict_proba(X),axis=1) # take argmax along row\n",
    "    \n",
    "lr = LogisticRegression(0.1,1500)\n",
    "print(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiClass Logistic Regression Object with coefficients:\n",
      "[[ -3.16384944e-01   3.11871606e-01   1.92616320e-01   1.24426019e-01\n",
      "   -1.64743318e-01  -7.14583433e-03   1.36211566e-01   1.91117638e-01\n",
      "    4.11670383e-01   1.41637279e-01  -2.21696359e-01  -2.84651620e-01\n",
      "    1.37133244e-01   4.64241998e-02  -1.29458514e-01   1.44426747e-01\n",
      "   -7.82113053e-01  -1.18525826e+00  -2.10153591e+00   3.52385843e+00\n",
      "    4.96093439e-01  -3.31854793e-01   7.26704678e-01  -3.38744015e-01\n",
      "   -4.94438588e-01   1.02169630e-01  -6.44720922e-01]\n",
      " [ -3.81898417e-01   2.12443557e-01   3.90683983e-01  -8.46257378e-02\n",
      "    1.64096577e-01   6.00138124e-01   2.80943393e-01   4.61967232e-01\n",
      "    8.52015501e-01   2.89078330e-01  -1.49177948e-02   3.10754833e-02\n",
      "    2.81545482e-01   1.46050949e-01  -3.06215218e-02   2.91697584e-01\n",
      "   -3.82610751e-01  -1.09152529e+00  -1.75708890e+00  -4.72292476e-01\n",
      "    4.18096642e-01  -8.52402100e-02  -2.69741378e-04  -2.50650513e-01\n",
      "    8.73527531e-02  -1.81013200e-02  -3.19241337e-01]\n",
      " [ -3.36933720e-01   7.27985830e-02   2.09027342e-01  -1.64746273e-01\n",
      "    1.22520617e-01   3.23304489e-01   1.80473965e-01   2.94811567e-01\n",
      "    5.64642772e-01   1.87332633e-01   9.54250902e-03  -5.95048239e-02\n",
      "    1.81077879e-01   6.11937914e-02  -2.11326969e-02   1.81125855e-01\n",
      "    4.51192313e-02  -2.00579079e-01  -3.37293307e-01  -1.16577969e+00\n",
      "    2.12859828e-01  -9.54609927e-02  -2.03291495e-01  -1.74111313e-01\n",
      "    5.55462137e-02  -1.30388416e-01  -1.49089193e-01]\n",
      " [ -2.96007528e-01  -1.35565154e-01   2.09257935e-02  -5.33766866e-01\n",
      "   -6.93441958e-04  -6.75389860e-02  -6.27483363e-02  -1.44883183e-01\n",
      "   -2.85127452e-01  -6.73673740e-02   8.00073175e-02   1.53406043e-01\n",
      "   -6.27554578e-02  -6.95085206e-02  -1.35882532e-02  -6.42390566e-02\n",
      "    5.62356081e-01   8.41072607e-01   1.46761111e+00  -1.17184095e+00\n",
      "   -2.17047378e-01  -2.39417300e-01  -2.68080075e-01   2.98083369e-01\n",
      "   -2.32313167e-02  -2.36653079e-01   2.40589862e-01]\n",
      " [ -2.31417244e-01  -2.01737935e-01   3.00711076e-02  -4.87747654e-01\n",
      "   -1.04942464e-01  -8.49149461e-01  -1.23517237e-01  -5.20371913e-01\n",
      "   -1.34974271e+00  -1.34130573e-01   2.91370330e-01   3.76534126e-01\n",
      "   -1.25096720e-01  -5.59116995e-02   1.70816854e-01  -1.29474801e-01\n",
      "    5.30342922e-01   1.16008608e+00   1.81448812e+00  -1.24078478e+00\n",
      "   -5.25115110e-01   8.90948777e-01  -9.22920347e-02   8.81077736e-01\n",
      "   -4.13991183e-01  -4.22304750e-01   6.30574965e-01]]\n",
      "Accuracy of:  0.185255712731\n"
     ]
    }
   ],
   "source": [
    "## %%time\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "lr = LogisticRegression(0.1,1000)\n",
    "lr.fit(X_train,y_train)\n",
    "print(lr)\n",
    "\n",
    "yhat = lr.predict(X_test)\n",
    "print('Accuracy of: ',accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAD8CAYAAACB3pQWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nF0KIWez/A2MmkB1cqCEFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19d93605cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# linear boundaries visualization from sklearn documentation\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_decision_boundaries(lr,Xin,y,title=''):\n",
    "    Xb = copy.deepcopy(Xin)\n",
    "    \n",
    "    # pick two random columns\n",
    "    (one, two) = np.random.randint(0,X.shape[1], 2)\n",
    "    \n",
    "    \n",
    "    lr.fit(Xb[:,(one, two)],y) # train only on two features\n",
    "\n",
    "    h=0.01\n",
    "    # create a mesh to plot in\n",
    "    x_min, x_max = Xb[:, 0].min() - 1, Xb[:, 0].max() + 1\n",
    "    y_min, y_max = Xb[:, 1].min() - 1, Xb[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # get prediction values\n",
    "    Z = lr.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.5)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(Xb[:, 0], Xb[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "    plt.xlabel(stats.columns[one])\n",
    "    plt.ylabel(stats.columns[two])\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "lr = LogisticRegression(0.1,1500) # this is still OUR LR implementation\n",
    "plot_decision_boundaries(lr,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Logistic Regression Object with coefficients:\n",
      "[[ 100.8240577 ]\n",
      " [ -38.02762117]\n",
      " [ -36.38648063]\n",
      " [ 338.5865417 ]\n",
      " [  -3.71530316]\n",
      " [  62.74259541]\n",
      " [ -60.67104796]\n",
      " [ -56.55537161]\n",
      " [ -47.63471685]\n",
      " [ -60.93564562]\n",
      " [  -8.19032175]\n",
      " [  49.34692206]\n",
      " [ -60.66036577]\n",
      " [ -32.31810938]\n",
      " [ -20.14227123]\n",
      " [ -60.52391986]\n",
      " [ -32.6296847 ]\n",
      " [  -1.44844092]\n",
      " [  26.95226457]\n",
      " [ -38.21490233]\n",
      " [ -49.75933184]\n",
      " [ -48.83349714]\n",
      " [ -37.61932445]\n",
      " [ -14.06564886]\n",
      " [  86.78708327]\n",
      " [ 115.94097107]\n",
      " [  27.97562714]]\n",
      "Accuracy of:  0.199891186072\n"
     ]
    }
   ],
   "source": [
    "# from last time, our logistic regression algorithm is given by (including everything we previously had):\n",
    "class BinaryLogisticRegression:\n",
    "    def __init__(self, eta, iterations=20, C=0.001, regularization='L2'):\n",
    "        self.eta = eta\n",
    "        self.iterations = iterations\n",
    "        self.C = C\n",
    "        self.regularization = regularization\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "        \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'Binary Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained Binary Logistic Regression Object'\n",
    "        \n",
    "    # convenience, private:\n",
    "    @staticmethod\n",
    "    def _add_bias(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # vectorized gradient calculation with regularization using L2 Norm\n",
    "    def _get_gradient(self,X,y):\n",
    "        \n",
    "        yhat = self.predict_proba(X, add_bias=False).ravel()[:, np.newaxis]\n",
    "        ydiff = y-yhat # get y difference\n",
    "\n",
    "        \n",
    "        gradient = np.mean(X * ydiff, axis=0) # make ydiff a column vector and multiply through\n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        \n",
    "        # gradient will be different depending on which regularization technique we use\n",
    "    \n",
    "        gradient[1:] \n",
    "        L1 = np.sign(w_[1:]) * self.C\n",
    "        L2 = -2 * self.w_[1:] * self.C\n",
    "        if (self.regularization=='L1'):\n",
    "            gradient[1:] += L1\n",
    "        if (self.regularization == 'L2'):\n",
    "            gradient[1:] += L2\n",
    "        if (self.regularization == 'L1/L2'):\n",
    "            gradient[1:] += (L1 + L2)\n",
    "        return gradient\n",
    "    \n",
    "    # public:\n",
    "    def predict_proba(self,X,add_bias=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_bias(X) if add_bias else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5) #return the actual prediction\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iterations):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            self.w_ += gradient*self.eta # multiply by learning rate \n",
    "\n",
    "blr = BinaryLogisticRegression(eta=0.1,iterations=500,C=0.001)\n",
    "\n",
    "blr.fit(X,y)\n",
    "print(blr)\n",
    "\n",
    "yhat = blr.predict(X)\n",
    "print('Accuracy of: ',accuracy_score(y,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "class LRClassifier:\n",
    "    def __init__(self, eta, iterations=20, C=0.001, optimization='full', regularization='L2'):\n",
    "        self.eta = eta\n",
    "        self.iterations = iterations\n",
    "        self.C = C\n",
    "        self.opt = optimization\n",
    "        self.regularization = regularization\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained MultiClass Logistic Regression Object'\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.unique(y) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = [] # will fill this array with binary classifiers\n",
    "        \n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = y==yval # create a binary problem\n",
    "            \n",
    "            \n",
    "            # train the binary classifier for this class\n",
    "            if (self.opt == 'stochastic'):\n",
    "                blr = StochasticLogisticRegression(self.eta, self.iterations, self.C, self.regularization)\n",
    "            elif (self.opt == 'hessian'):\n",
    "                blr = HessianBinaryLogisticRegression(self.eta, self.iterations, self.C, self.regularization)\n",
    "            elif (self.opt == 'bfgs'):\n",
    "                blr = BFGSBinaryLogisticRegression(_, 3, self.C, self.regularization)\n",
    "            else:\n",
    "                blr = BinaryLogisticRegression(self.eta, self.iterations, self.C, self.regularization)\n",
    "            \n",
    "            blr.fit(X,y_binary)\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(blr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        probs = []\n",
    "        for blr in self.classifiers_:\n",
    "            probs.append(blr.predict_proba(X)) # get probability for each classifier\n",
    "        \n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return np.argmax(self.predict_proba(X),axis=1) # take argmax along row\n",
    "\n",
    "    def score(self,*args, **kwargs):\n",
    "        yhat = self.predict(X)\n",
    "        return accuracy_score(y, yhat)\n",
    "    \n",
    "    # lifted straight out of sklearn source code with some modifications\n",
    "    @classmethod\n",
    "    def _get_param_names(cls):\n",
    "        # this is just specific to this classifier\n",
    "        return sorted(['eta', 'iterations', 'C', 'optimization', 'regularization'])\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\"Get parameters for this estimator.\n",
    "        Parameters\n",
    "        ----------\n",
    "        deep : boolean, optional\n",
    "            If True, will return the parameters for this estimator and\n",
    "            contained subobjects that are estimators.\n",
    "        Returns\n",
    "        -------\n",
    "        params : mapping of string to any\n",
    "            Parameter names mapped to their values.\n",
    "        \"\"\"\n",
    "        out = dict()\n",
    "        for key in self._get_param_names():\n",
    "            # We need deprecation warnings to always be on in order to\n",
    "            # catch deprecated param values.\n",
    "            # This is set in utils/__init__.py but it gets overwritten\n",
    "            # when running under python3 somehow.\n",
    "            warnings.simplefilter(\"always\", DeprecationWarning)\n",
    "            try:\n",
    "                with warnings.catch_warnings(record=True) as w:\n",
    "                    value = getattr(self, key, None)\n",
    "                if len(w) and w[0].category == DeprecationWarning:\n",
    "                    # if the parameter is deprecated, don't show it\n",
    "                    continue\n",
    "            finally:\n",
    "                warnings.filters.pop(0)\n",
    "\n",
    "            # XXX: should we rather test if instance of estimator?\n",
    "            if deep and hasattr(value, 'get_params'):\n",
    "                deep_items = value.get_params().items()\n",
    "                out.update((key + '__' + k, val) for k, val in deep_items)\n",
    "            out[key] = value\n",
    "        return out\n",
    "     \n",
    "    def set_params(self, **params):\n",
    "        \"\"\"Set the parameters of this estimator.\n",
    "        The method works on simple estimators as well as on nested objects\n",
    "        (such as pipelines). The latter have parameters of the form\n",
    "        ``<component>__<parameter>`` so that it's possible to update each\n",
    "        component of a nested object.\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        if not params:\n",
    "            # Simple optimization to gain speed (inspect is slow)\n",
    "            return self\n",
    "        valid_params = self.get_params(deep=True)\n",
    "        # changed from six.iteritems() bc no need for py2 vs py3 compatabillity\n",
    "        for key, value in params.items():\n",
    "            split = key.split('__', 1)\n",
    "            if len(split) > 1:\n",
    "                # nested objects case\n",
    "                name, sub_name = split\n",
    "                if name not in valid_params:\n",
    "                    raise ValueError('Invalid parameter %s for estimator %s. '\n",
    "                                     'Check the list of available parameters '\n",
    "                                     'with `estimator.get_params().keys()`.' %\n",
    "                                     (name, self))\n",
    "                sub_object = valid_params[name]\n",
    "                sub_object.set_params(**{sub_name: value})\n",
    "            else:\n",
    "                # simple objects case\n",
    "                if key not in valid_params:\n",
    "                    raise ValueError('Invalid parameter %s for estimator %s. '\n",
    "                                     'Check the list of available parameters '\n",
    "                                     'with `estimator.get_params().keys()`.' %\n",
    "                                     (key, self.__class__.__name__))\n",
    "                setattr(self, key, value)\n",
    "        return self\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=<__main__.LRClassifier object at 0x0000019D93601A20>,\n",
       "       fit_params=None, iid=True, n_jobs=1, param_grid={'C': [1, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'C':[1, 5, 10]}\n",
    "lrc = LRClassifier(eta=0.1)\n",
    "clf = GridSearchCV(lrc, parameters)\n",
    "clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.2819736 ,  0.26479952,  0.25956043]),\n",
       " 'mean_score_time': array([ 0.01977348,  0.01562738,  0.01562659]),\n",
       " 'mean_test_score': array([ 0.16706502,  0.17582407,  0.19385168]),\n",
       " 'mean_train_score': array([ 0.16706565,  0.17582517,  0.19385201]),\n",
       " 'param_C': masked_array(data = [1 5 10],\n",
       "              mask = [False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'C': 1}, {'C': 5}, {'C': 10}],\n",
       " 'rank_test_score': array([3, 2, 1]),\n",
       " 'split0_test_score': array([ 0.0984222 ,  0.09989119,  0.19113166]),\n",
       " 'split0_train_score': array([ 0.0984222 ,  0.09989119,  0.19113166]),\n",
       " 'split1_test_score': array([ 0.22404788,  0.23144723,  0.19047878]),\n",
       " 'split1_train_score': array([ 0.22404788,  0.23144723,  0.19047878]),\n",
       " 'split2_test_score': array([ 0.17872688,  0.19613711,  0.19994559]),\n",
       " 'split2_train_score': array([ 0.17872688,  0.19613711,  0.19994559]),\n",
       " 'std_fit_time': array([ 0.01939531,  0.00316119,  0.00914496]),\n",
       " 'std_score_time': array([  6.39836968e-03,   5.15042996e-07,   2.97360213e-07]),\n",
       " 'std_test_score': array([ 0.05194645,  0.05559615,  0.00431693]),\n",
       " 'std_train_score': array([ 0.05194511,  0.05559484,  0.00431705])}"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18416757344940152"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc = LRClassifier(eta=0.1, C=10)\n",
    "lrc.fit(X_train,y_train)\n",
    "accuracy_score(y_test,lrc.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlenv]",
   "language": "python",
   "name": "conda-env-mlenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
