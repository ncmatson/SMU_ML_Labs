{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8\n",
    "Cameron Matson\n",
    "\n",
    "Zihao Mao\n",
    "\n",
    "Yichen Duan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Music Reviews\n",
    "\n",
    "Our data set consists of every review from pitchfork.com since 1999, a total of 18,393 reviews of muisc albums.  Accompanied with the full lenght review, each album is rated on a scale from 0 to 10, 10 being the highest.  What we'd like to do is use a recurrent neural network to predict, from the text of the review itself, whether the reviewer gave the album a high score (7-10), a neutral score (4-7), or a low score (0-3).\n",
    "\n",
    "One of the most common uses of sentiment analysis is to classify social media posts.  This type of information can then be used by marketing professionals as a sort of consumer survey.  This could potentially be used by music labels as well.  A music label might collect tweets, or facebook posts, or even articles on the web that mention an album that they recently released.  Then they could use our model (trained on the pitchfork reviews) to classify whether there is a consesus (or not) on how the album was recieved.\n",
    "\n",
    "In terms of metrics, since the business case is essentially to replace human observers of the data, and we probably won't have someone observing the output at the end (because then whats the point) accuracy is probably the best metric to use when evaluating our performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep\n",
    "\n",
    "The data is stored in two separate `csv` files, one that has the reviews in it, and one that has a bunch of meta data, including the score, in a different one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reviews: 18393\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18393 entries, 0 to 18392\n",
      "Data columns (total 2 columns):\n",
      "reviewid    18393 non-null int64\n",
      "content     18383 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 287.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewid</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22703</td>\n",
       "      <td>“Trip-hop” eventually became a ’90s punchline,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22721</td>\n",
       "      <td>Eight years, five albums, and two EPs in, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22659</td>\n",
       "      <td>Minneapolis’ Uranium Club seem to revel in bei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22661</td>\n",
       "      <td>Kleenex began with a crash. It transpired one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22725</td>\n",
       "      <td>It is impossible to consider a given release b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewid                                            content\n",
       "0     22703  “Trip-hop” eventually became a ’90s punchline,...\n",
       "1     22721  Eight years, five albums, and two EPs in, the ...\n",
       "2     22659  Minneapolis’ Uranium Club seem to revel in bei...\n",
       "3     22661  Kleenex began with a crash. It transpired one ...\n",
       "4     22725  It is impossible to consider a given release b..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "reviews = pd.read_csv('../data/reviews.csv', encoding='utf-8')\n",
    "print('number of reviews:',len(reviews))\n",
    "reviews.info()\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18393 entries, 0 to 18392\n",
      "Data columns (total 13 columns):\n",
      "reviewid          18393 non-null int64\n",
      "title             18391 non-null object\n",
      "artist            18391 non-null object\n",
      "url               18393 non-null object\n",
      "score             18393 non-null float64\n",
      "best_new_music    18393 non-null int64\n",
      "author            18393 non-null object\n",
      "author_type       14487 non-null object\n",
      "pub_date          18393 non-null object\n",
      "pub_weekday       18393 non-null int64\n",
      "pub_day           18393 non-null int64\n",
      "pub_month         18393 non-null int64\n",
      "pub_year          18393 non-null int64\n",
      "dtypes: float64(1), int64(6), object(6)\n",
      "memory usage: 1.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewid</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "      <th>best_new_music</th>\n",
       "      <th>author</th>\n",
       "      <th>author_type</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>pub_weekday</th>\n",
       "      <th>pub_day</th>\n",
       "      <th>pub_month</th>\n",
       "      <th>pub_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22703</td>\n",
       "      <td>mezzanine</td>\n",
       "      <td>massive attack</td>\n",
       "      <td>http://pitchfork.com/reviews/albums/22703-mezz...</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0</td>\n",
       "      <td>nate patrin</td>\n",
       "      <td>contributor</td>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22721</td>\n",
       "      <td>prelapsarian</td>\n",
       "      <td>krallice</td>\n",
       "      <td>http://pitchfork.com/reviews/albums/22721-prel...</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0</td>\n",
       "      <td>zoe camp</td>\n",
       "      <td>contributor</td>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22659</td>\n",
       "      <td>all of them naturals</td>\n",
       "      <td>uranium club</td>\n",
       "      <td>http://pitchfork.com/reviews/albums/22659-all-...</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0</td>\n",
       "      <td>david glickman</td>\n",
       "      <td>contributor</td>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22661</td>\n",
       "      <td>first songs</td>\n",
       "      <td>kleenex, liliput</td>\n",
       "      <td>http://pitchfork.com/reviews/albums/22661-firs...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>jenn pelly</td>\n",
       "      <td>associate reviews editor</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22725</td>\n",
       "      <td>new start</td>\n",
       "      <td>taso</td>\n",
       "      <td>http://pitchfork.com/reviews/albums/22725-new-...</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0</td>\n",
       "      <td>kevin lozano</td>\n",
       "      <td>tracks coordinator</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewid                 title            artist  \\\n",
       "0     22703             mezzanine    massive attack   \n",
       "1     22721          prelapsarian          krallice   \n",
       "2     22659  all of them naturals      uranium club   \n",
       "3     22661           first songs  kleenex, liliput   \n",
       "4     22725             new start              taso   \n",
       "\n",
       "                                                 url  score  best_new_music  \\\n",
       "0  http://pitchfork.com/reviews/albums/22703-mezz...    9.3               0   \n",
       "1  http://pitchfork.com/reviews/albums/22721-prel...    7.9               0   \n",
       "2  http://pitchfork.com/reviews/albums/22659-all-...    7.3               0   \n",
       "3  http://pitchfork.com/reviews/albums/22661-firs...    9.0               1   \n",
       "4  http://pitchfork.com/reviews/albums/22725-new-...    8.1               0   \n",
       "\n",
       "           author               author_type    pub_date  pub_weekday  pub_day  \\\n",
       "0     nate patrin               contributor  2017-01-08            6        8   \n",
       "1        zoe camp               contributor  2017-01-07            5        7   \n",
       "2  david glickman               contributor  2017-01-07            5        7   \n",
       "3      jenn pelly  associate reviews editor  2017-01-06            4        6   \n",
       "4    kevin lozano        tracks coordinator  2017-01-06            4        6   \n",
       "\n",
       "   pub_month  pub_year  \n",
       "0          1      2017  \n",
       "1          1      2017  \n",
       "2          1      2017  \n",
       "3          1      2017  \n",
       "4          1      2017  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.read_csv('../data/meta.csv')\n",
    "meta.info()\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18393 entries, 0 to 18392\n",
      "Data columns (total 2 columns):\n",
      "reviewid    18393 non-null int64\n",
      "score       18393 non-null float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 287.5 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewid</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22703</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22721</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22659</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22661</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22725</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewid  score\n",
       "0     22703    9.3\n",
       "1     22721    7.9\n",
       "2     22659    7.3\n",
       "3     22661    9.0\n",
       "4     22725    8.1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.drop(['title','artist', 'url', 'author', 'author_type', 'best_new_music', 'pub_date', 'pub_weekday', 'pub_day', 'pub_month', 'pub_year'], axis=1, inplace=True)\n",
    "meta.info()\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18391 entries, 0 to 18400\n",
      "Data columns (total 2 columns):\n",
      "content    18391 non-null object\n",
      "score      18391 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 431.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“Trip-hop” eventually became a ’90s punchline,...</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eight years, five albums, and two EPs in, the ...</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Minneapolis’ Uranium Club seem to revel in bei...</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kleenex began with a crash. It transpired one ...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It is impossible to consider a given release b...</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  score\n",
       "0  “Trip-hop” eventually became a ’90s punchline,...    9.3\n",
       "1  Eight years, five albums, and two EPs in, the ...    7.9\n",
       "2  Minneapolis’ Uranium Club seem to revel in bei...    7.3\n",
       "3  Kleenex began with a crash. It transpired one ...    9.0\n",
       "4  It is impossible to consider a given release b...    8.1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(reviews, meta, on='reviewid')\n",
    "df.drop('reviewid', axis=1, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally lets group the score column so that we have a categorical target variable.  And then take a look at the distribution of the classes we set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAEMZJREFUeJzt3X+s3XV9x/Hna634c1qQq2Fts7LY\nOJFMZQ2ykSwLGChgLH9IUrJJ45o0WXDDzURh+4NMJYFsEUemLI10lo2ABF1oBGUNYMwS+XERhkBl\nvQEGdzB7TQF1RFzxvT/up9uRz+2Pe07bc+t9PpKT8/2+v5/v9/s+30Bf/f44p6kqJEka9CvjbkCS\ntPAYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeosHXcDwzr++ONr1apV425Dko4q\nDzzwwA+rauJA447acFi1ahWTk5PjbkOSjipJ/uNgxnlZSZLUMRwkSR3DQZLUMRwkSZ0DhkOSLUl2\nJXlkoPbXSb6f5OEk/5xk2cCyy5JMJXk8ydkD9bWtNpXk0oH6iUnuTbIzyVeSHHMoP6Akaf4O5szh\ny8DaV9W2AydX1W8B/w5cBpDkJGA98O62zheTLEmyBPgCcA5wEnBhGwtwFXB1Va0Gngc2jvSJJEkj\nO2A4VNW3gd2vqv1LVe1ps/cAK9r0OuCmqnq5qp4EpoBT22uqqp6oqp8BNwHrkgQ4A7ilrb8VOH/E\nzyRJGtGhuOfwR8A32vRy4JmBZdOttq/6W4EXBoJmb12SNEYjhUOSvwT2ADfsLc0xrIao72t/m5JM\nJpmcmZmZb7uSpIM09Dekk2wAPgicWVV7/0CfBlYODFsBPNum56r/EFiWZGk7exgc36mqzcBmgDVr\n1uwzRKTFatWlt427hSPqqSvPG3cLv7SGOnNIshb4FPChqnppYNE2YH2S1yY5EVgN3AfcD6xuTyYd\nw+xN620tVO4GPtzW3wDcOtxHkSQdKgfzKOuNwHeAdyaZTrIR+DvgV4HtSR5K8vcAVfUocDPwGPBN\n4OKqeqWdFXwMuAPYAdzcxsJsyPx5kilm70Fcd0g/oSRp3g54WamqLpyjvM8/wKvqCuCKOeq3A7fP\nUX+C2aeZJEkLhN+QliR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdw\nkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1\nDAdJUsdwkCR1DAdJUueA4ZBkS5JdSR4ZqB2XZHuSne392FZPkmuSTCV5OMkpA+tsaON3JtkwUP/t\nJN9r61yTJIf6Q0qS5udgzhy+DKx9Ve1S4M6qWg3c2eYBzgFWt9cm4FqYDRPgcuD9wKnA5XsDpY3Z\nNLDeq/clSTrCDhgOVfVtYPeryuuArW16K3D+QP36mnUPsCzJCcDZwPaq2l1VzwPbgbVt2Zur6jtV\nVcD1A9uSJI3JsPcc3l5VzwG097e1+nLgmYFx0622v/r0HHVJ0hgd6hvSc90vqCHqc2882ZRkMsnk\nzMzMkC1Kkg5k2HD4QbskRHvf1erTwMqBcSuAZw9QXzFHfU5Vtbmq1lTVmomJiSFblyQdyLDhsA3Y\n+8TRBuDWgfpF7aml04AX22WnO4CzkhzbbkSfBdzRlv04yWntKaWLBrYlSRqTpQcakORG4PeB45NM\nM/vU0ZXAzUk2Ak8DF7ThtwPnAlPAS8BHAapqd5LPAPe3cZ+uqr03uf+Y2SeiXg98o70kSWN0wHCo\nqgv3sejMOcYWcPE+trMF2DJHfRI4+UB9SJKOHL8hLUnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7h\nIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnq\nGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpM5I4ZDkz5I8muSRJDcmeV2SE5Pcm2Rnkq8k\nOaaNfW2bn2rLVw1s57JWfzzJ2aN9JEnSqIYOhyTLgT8F1lTVycASYD1wFXB1Va0Gngc2tlU2As9X\n1TuAq9s4kpzU1ns3sBb4YpIlw/YlSRrdqJeVlgKvT7IUeAPwHHAGcEtbvhU4v02va/O05WcmSavf\nVFUvV9WTwBRw6oh9SZJGMHQ4VNV/An8DPM1sKLwIPAC8UFV72rBpYHmbXg4809bd08a/dbA+xzq/\nIMmmJJNJJmdmZoZtXZJ0AKNcVjqW2b/1nwj8GvBG4Jw5htbeVfaxbF/1vli1uarWVNWaiYmJ+Tct\nSTooo1xW+gDwZFXNVNX/AF8DfhdY1i4zAawAnm3T08BKgLb8LcDuwfoc60iSxmCUcHgaOC3JG9q9\ngzOBx4C7gQ+3MRuAW9v0tjZPW35XVVWrr29PM50IrAbuG6EvSdKIlh54yNyq6t4ktwDfBfYADwKb\ngduAm5J8ttWua6tcB/xjkilmzxjWt+08muRmZoNlD3BxVb0ybF+SpNENHQ4AVXU5cPmryk8wx9NG\nVfVT4IJ9bOcK4IpRepEkHTp+Q1qS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS\n1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEc\nJEkdw0GS1DEcJEkdw0GS1BkpHJIsS3JLku8n2ZHkd5Icl2R7kp3t/dg2NkmuSTKV5OEkpwxsZ0Mb\nvzPJhlE/lCRpNKOeOfwt8M2q+k3gPcAO4FLgzqpaDdzZ5gHOAVa31ybgWoAkxwGXA+8HTgUu3xso\nkqTxGDockrwZ+D3gOoCq+llVvQCsA7a2YVuB89v0OuD6mnUPsCzJCcDZwPaq2l1VzwPbgbXD9iVJ\nGt0oZw6/AcwA/5DkwSRfSvJG4O1V9RxAe39bG78ceGZg/elW21ddkjQmo4TDUuAU4Nqqeh/w3/z/\nJaS5ZI5a7afebyDZlGQyyeTMzMx8+5UkHaRRwmEamK6qe9v8LcyGxQ/a5SLa+66B8SsH1l8BPLuf\neqeqNlfVmqpaMzExMULrkqT9GTocquq/gGeSvLOVzgQeA7YBe5842gDc2qa3ARe1p5ZOA15sl53u\nAM5Kcmy7EX1Wq0mSxmTpiOv/CXBDkmOAJ4CPMhs4NyfZCDwNXNDG3g6cC0wBL7WxVNXuJJ8B7m/j\nPl1Vu0fsS5I0gpHCoaoeAtbMsejMOcYWcPE+trMF2DJKL5KkQ8dvSEuSOoaDJKljOEiSOoaDJKlj\nOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiS\nOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKkzcjgkWZLkwSRfb/MnJrk3\nyc4kX0lyTKu/ts1PteWrBrZxWas/nuTsUXuSJI3mUJw5XALsGJi/Cri6qlYDzwMbW30j8HxVvQO4\nuo0jyUnAeuDdwFrgi0mWHIK+JElDGikckqwAzgO+1OYDnAHc0oZsBc5v0+vaPG35mW38OuCmqnq5\nqp4EpoBTR+lLkjSaUc8cPg98Evh5m38r8EJV7Wnz08DyNr0ceAagLX+xjf+/+hzrSJLGYOhwSPJB\nYFdVPTBYnmNoHWDZ/tZ59T43JZlMMjkzMzOvfiVJB2+UM4fTgQ8leQq4idnLSZ8HliVZ2sasAJ5t\n09PASoC2/C3A7sH6HOv8gqraXFVrqmrNxMTECK1LkvZn6HCoqsuqakVVrWL2hvJdVfUHwN3Ah9uw\nDcCtbXpbm6ctv6uqqtXXt6eZTgRWA/cN25ckaXRLDzxk3j4F3JTks8CDwHWtfh3wj0mmmD1jWA9Q\nVY8muRl4DNgDXFxVrxyGviRJB+mQhENVfQv4Vpt+gjmeNqqqnwIX7GP9K4ArDkUvkqTR+Q1pSVLH\ncJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQ7Hr7JK0hGx\n6tLbxt3CEffUlecdkf145iBJ6hgOkqSO4SBJ6njPQb+0FuP1aOlQ8cxBktQxHCRJHcNBktQxHCRJ\nHcNBktQxHCRJHcNBktQxHCRJHcNBktQZOhySrExyd5IdSR5NckmrH5dke5Kd7f3YVk+Sa5JMJXk4\nySkD29rQxu9MsmH0jyVJGsUoZw57gE9U1buA04CLk5wEXArcWVWrgTvbPMA5wOr22gRcC7NhAlwO\nvB84Fbh8b6BIksZj6HCoqueq6rtt+sfADmA5sA7Y2oZtBc5v0+uA62vWPcCyJCcAZwPbq2p3VT0P\nbAfWDtuXJGl0h+SeQ5JVwPuAe4G3V9VzMBsgwNvasOXAMwOrTbfavupz7WdTkskkkzMzM4eidUnS\nHEYOhyRvAr4KfLyqfrS/oXPUaj/1vli1uarWVNWaiYmJ+TcrSTooI4VDktcwGww3VNXXWvkH7XIR\n7X1Xq08DKwdWXwE8u5+6JGlMRnlaKcB1wI6q+tzAom3A3ieONgC3DtQvak8tnQa82C473QGcleTY\ndiP6rFaTJI3JKP/Yz+nAR4DvJXmo1f4CuBK4OclG4GnggrbsduBcYAp4CfgoQFXtTvIZ4P427tNV\ntXuEviRJIxo6HKrqX5n7fgHAmXOML+DifWxrC7Bl2F4kSYeW35CWJHUMB0lSx3CQJHUMB0lSx3CQ\nJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUM\nB0lSx3CQJHWG/jekdXRZdelt425B0lHEMwdJUsdwkCR1DAdJUsdwkCR1DAdJUmfBhEOStUkeTzKV\n5NJx9yNJi9mCCIckS4AvAOcAJwEXJjlpvF1J0uK1UL7ncCowVVVPACS5CVgHPHY4duYz/5K0fwvi\nzAFYDjwzMD/dapKkMVgoZw6Zo1bdoGQTsKnN/iTJ40Pu73jgh0Ouuxh5vObH4zU/Hq95yFUjH69f\nP5hBCyUcpoGVA/MrgGdfPaiqNgObR91ZksmqWjPqdhYLj9f8eLzmx+M1P0fqeC2Uy0r3A6uTnJjk\nGGA9sG3MPUnSorUgzhyqak+SjwF3AEuALVX16JjbkqRFa0GEA0BV3Q7cfoR2N/KlqUXG4zU/Hq/5\n8XjNzxE5Xqnq7vtKkha5hXLPQZK0gCyqcPAnOuYnyZYku5I8Mu5ejgZJVia5O8mOJI8muWTcPS1k\nSV6X5L4k/9aO11+Nu6ejQZIlSR5M8vXDuZ9FEw7+RMdQvgysHXcTR5E9wCeq6l3AacDF/je2Xy8D\nZ1TVe4D3AmuTnDbmno4GlwA7DvdOFk04MPATHVX1M2DvT3RoH6rq28DucfdxtKiq56rqu236x8z+\nD+w3/fehZv2kzb6mvbwJuh9JVgDnAV863PtaTOHgT3ToiEmyCngfcO94O1nY2iWSh4BdwPaq8njt\n3+eBTwI/P9w7WkzhcFA/0SGNKsmbgK8CH6+qH427n4Wsql6pqvcy+6sIpyY5edw9LVRJPgjsqqoH\njsT+FlM4HNRPdEijSPIaZoPhhqr62rj7OVpU1QvAt/Ae1/6cDnwoyVPMXhY/I8k/Ha6dLaZw8Cc6\ndFglCXAdsKOqPjfufha6JBNJlrXp1wMfAL4/3q4Wrqq6rKpWVNUqZv/8uquq/vBw7W/RhENV7QH2\n/kTHDuBmf6Jj/5LcCHwHeGeS6SQbx93TAnc68BFm/0b3UHudO+6mFrATgLuTPMzsX962V9VhfTxT\nB89vSEuSOovmzEGSdPAMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lS538BtEuLto1VVXMA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x196b08909e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "labels = np.arange(NUM_CLASSES)\n",
    "df['target'] = pd.cut(df.score, NUM_CLASSES, labels=labels)\n",
    "df.head()\n",
    "\n",
    "plt.hist(df.target, bins=NUM_CLASSES)\n",
    "plt.xticks(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we're pretty top heavy in terms of the number of reviews for each score.  That's okay, we just need to make sure that our splits are stratified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#finally lets reduce the number of articles we're working with\n",
    "NUM_SAMPLES = 5000\n",
    "df = df.sample(n=NUM_SAMPLES, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Waco Brothers should be awful. There shouldn\\'t be any way possible on\\n    God\\'s green earth that a British art-punk with anarchosyndicalist leanings\\n    could put together a band that includes an acknowledged ex-member of KMFDM\\n    on pedal steel guitar and make credible-sounding circa-1960 roots country.\\n    Worse, this lot of expats do it a lot better than most Americans of the same\\n    ilk.\\n    \\n    Admit it. It rankles a little bit when someone from exotic climes with his or\\n    her own cultural legacy waiting to be exploited comes along and exploits ours\\n    better than we do. By all rights, Jon Langford\\'s roots project ought to be a\\n    collection of rockin\\' madrigals and ballads about flowers. We\\'ve got a brace\\n    of alt-country upstarts who can defame our glorious traditions just fine,\\n    thanks. Where does this pack of goofy bastards get off thinking they can\\n    one-up our national heritage?\\n    \\n    But they do, damn it. Jon Langford has always utilized his extracurricular\\n    time with the Wacos to exorcise the C&W; demons that have lurked in his work\\n    with the Mekons since the 1980s. Where great Mekons albums integrate a vaguely\\n    folkish, space cowboy vibe, the Waco Brothers sound like real-deal ten-gallon\\n    hatters with a grouchy streak and a subscription to The Nation. There\\n    are no body-positive-feminist allegories about pirates to be found here. Sure,\\n    there\\'s a William Blake nod on occasion, but mostly, Langford and\\n    co-singer/songwriter Dean Schlabowske invoke the spirit of the common man,\\n    crank up the hollow-body guitars and rock their wary ways.\\n    \\n    Hoping for artistic growth is completely off the subject when talking about\\n    the Waco Brothers. After all, the band\\'s an acknowledged nostalgia act. All\\n    the same, despite its bellicose title, Electric Waco Chair finds our\\n    boys in a relatively contemplative mood: the songs center generally on getting\\n    older; the tempos aren\\'t nearly as frantic as they\\'ve been in the past; and\\n    the jokes here are at least a little bit subtler. The Wacos still want to be\\n    the party band in the honky-tonk at the end of the world, but they\\'ve come to\\n    realize they need a couple slow jams for couples to dance to.\\nChair, eager to please as other Waco offerings, includes a brace of\\n    crowdpleasers. The air of scabrousness that hovers over most Mekons projects\\n    isn\\'t anywhere to be found here, replaced instead with a rummy goodheartedness\\n    in short supply among independent-label socialists these days. Langford seems\\n    unnecessarily into channeling Billy Bragg at times-- particularly on the\\n    egregious \"Walking on Hell\\'s Roof Looking at the Flowers\"-- and some of the\\n    arrangements are a little shticky, like when the Brothers attempt a\\n    Spanish-flavored feel on \"Cornered.\"  But nit-picking individual moments here\\n    is pointless spoil-sportsmanship. It\\'s like going to a great rent party and\\n    complaining that the beer sucks.\\n    \\n    The Waco Brothers aren\\'t about flawless, detailed songcraft. They\\'re about\\n    lager-soaked good times with just enough anxiety and doubt to make the trip\\n    worth taking.  And, in that respect, Electric Waco Chair never\\n    disappoints. Though these fellas don\\'t take the country idiom as seriously as\\n    your favorite American punk-countryist might, they sure have a great time\\n    doing their work.\\n    \\n    If anything, their irreverence toward country music is what separates the\\n    Waco Brothers from the herd. Where American revivalists are frustratingly\\n    serious about their music, treating country like holy writ, the Waco Brothers\\n    don\\'t have the same stake in it. Because it\\'s not their history, they can\\n    treat it as a contemporary event and return it to the go-for-broke fun spirit\\n    behind all that worship old-time tunage gets subjected to. Besides, who wants\\n    to listen to madrigals all day, anyhow?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is an array of the reviews\n",
    "texts = df.content.values\n",
    "texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use Keras's tokenizer module and pad_sequences to convert the texts into integer sequences of all the same length which makes the computation much easier and quicker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (5000, 1000)\n",
      "Shape of label tensor: (5000, 5)\n",
      "4999\n",
      "Wall time: 5.89 s\n"
     ]
    }
   ],
   "source": [
    "NUM_WORDS = 5000\n",
    "MAX_ART_LEN = 1000\n",
    "\n",
    "tkn = Tokenizer(num_words=NUM_WORDS)\n",
    "tkn.fit_on_texts(texts)\n",
    "\n",
    "sequences = tkn.texts_to_sequences(texts)\n",
    "X = pad_sequences(sequences, maxlen=MAX_ART_LEN)\n",
    "\n",
    "y = np.asanyarray(df.target)\n",
    "y_ohe = keras.utils.to_categorical(y)\n",
    "print('Shape of data tensor:', X.shape)\n",
    "print('Shape of label tensor:', y_ohe.shape)\n",
    "print(np.max(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN stuff\n",
    "\n",
    "Okay now our data is ready to use for in the rnn.\n",
    "\n",
    "We'll design two networks one using a LSTM cell and one using a GRU.  For each of them we'll try a few different hyper parameters first on each of them to see if we can find the best architecture.  After that we'll do a cross validation loop of five iterations on an 80/20 train/test split to evaluate the general performance\n",
    "\n",
    "The parameters we'll investigate are dropout/recurrent_dropout (we'll move these together as one variable) and the output dimension of the RNN cell.\n",
    "\n",
    "Both the LSTM and GRU architectures will have the same overall structure\n",
    "- embedding (which will be shared between the two architectures)\n",
    "- the rnn cell\n",
    "- 2 dense layers (one with a hidden number of neurons and the final with the number of classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "dropout_rates = [0.0, 0.2, 0.6]\n",
    "latent_dims = [10, 20, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** LSTM : 0.0 , 10 ********\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (InputLayer)              (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 1000, 50)          250000    \n",
      "_________________________________________________________________\n",
      "LSTM (LSTM)                  (None, 10)                2440      \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 252,765\n",
      "Trainable params: 252,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "****** LSTM : 0.0 , 20 ********\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (InputLayer)              (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 1000, 50)          250000    \n",
      "_________________________________________________________________\n",
      "LSTM (LSTM)                  (None, 20)                5680      \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 256,205\n",
      "Trainable params: 256,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "****** LSTM : 0.0 , 30 ********\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (InputLayer)              (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 1000, 50)          250000    \n",
      "_________________________________________________________________\n",
      "LSTM (LSTM)                  (None, 30)                9720      \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 260,445\n",
      "Trainable params: 260,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "****** LSTM : 0.2 , 10 ********\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (InputLayer)              (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 1000, 50)          250000    \n",
      "_________________________________________________________________\n",
      "LSTM (LSTM)                  (None, 10)                2440      \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 252,765\n",
      "Trainable params: 252,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "****** LSTM : 0.2 , 20 ********\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (InputLayer)              (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 1000, 50)          250000    \n",
      "_________________________________________________________________\n",
      "LSTM (LSTM)                  (None, 20)                5680      \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 256,205\n",
      "Trainable params: 256,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "****** LSTM : 0.2 , 30 ********\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (InputLayer)              (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 1000, 50)          250000    \n",
      "_________________________________________________________________\n",
      "LSTM (LSTM)                  (None, 30)                9720      \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 260,445\n",
      "Trainable params: 260,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "****** LSTM : 0.6 , 10 ********\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (InputLayer)              (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 1000, 50)          250000    \n",
      "_________________________________________________________________\n",
      "LSTM (LSTM)                  (None, 10)                2440      \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 252,765\n",
      "Trainable params: 252,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "****** LSTM : 0.6 , 20 ********\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (InputLayer)              (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 1000, 50)          250000    \n",
      "_________________________________________________________________\n",
      "LSTM (LSTM)                  (None, 20)                5680      \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 256,205\n",
      "Trainable params: 256,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** LSTM : 0.6 , 30 ********\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (InputLayer)              (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 1000, 50)          250000    \n",
      "_________________________________________________________________\n",
      "LSTM (LSTM)                  (None, 30)                9720      \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 260,445\n",
      "Trainable params: 260,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "****** GRU : 0.0 , 10 ********\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (InputLayer)              (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 1000, 50)          250000    \n",
      "_________________________________________________________________\n",
      "GRU (GRU)                    (None, 10)                1830      \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 252,155\n",
      "Trainable params: 252,155\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "****** GRU : 0.0 , 20 ********\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (InputLayer)              (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 1000, 50)          250000    \n",
      "_________________________________________________________________\n",
      "GRU (GRU)                    (None, 20)                4260      \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 254,785\n",
      "Trainable params: 254,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "****** GRU : 0.0 , 30 ********\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (InputLayer)              (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 1000, 50)          250000    \n",
      "_________________________________________________________________\n",
      "GRU (GRU)                    (None, 30)                7290      \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 258,015\n",
      "Trainable params: 258,015\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "****** GRU : 0.2 , 10 ********\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (InputLayer)              (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 1000, 50)          250000    \n",
      "_________________________________________________________________\n",
      "GRU (GRU)                    (None, 10)                1830      \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 252,155\n",
      "Trainable params: 252,155\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "****** GRU : 0.2 , 20 ********\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (InputLayer)              (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 1000, 50)          250000    \n",
      "_________________________________________________________________\n",
      "GRU (GRU)                    (None, 20)                4260      \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 254,785\n",
      "Trainable params: 254,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "****** GRU : 0.2 , 30 ********\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (InputLayer)              (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 1000, 50)          250000    \n",
      "_________________________________________________________________\n",
      "GRU (GRU)                    (None, 30)                7290      \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 258,015\n",
      "Trainable params: 258,015\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "****** GRU : 0.6 , 10 ********\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (InputLayer)              (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 1000, 50)          250000    \n",
      "_________________________________________________________________\n",
      "GRU (GRU)                    (None, 10)                1830      \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 252,155\n",
      "Trainable params: 252,155\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** GRU : 0.6 , 20 ********\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (InputLayer)              (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 1000, 50)          250000    \n",
      "_________________________________________________________________\n",
      "GRU (GRU)                    (None, 20)                4260      \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 254,785\n",
      "Trainable params: 254,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "****** GRU : 0.6 , 30 ********\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (InputLayer)              (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, 1000, 50)          250000    \n",
      "_________________________________________________________________\n",
      "GRU (GRU)                    (None, 30)                7290      \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 258,015\n",
      "Trainable params: 258,015\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "EMBED_SIZE = 50\n",
    "\n",
    "archs = ['LSTM', 'GRU']\n",
    "rnns = []\n",
    "\n",
    "dropout = dropout_rates[0]\n",
    "latent_dim = latent_dims[0]\n",
    "\n",
    "input_holder = Input(shape=(MAX_ART_LEN, ), name='in')\n",
    "shared_embed = Embedding(NUM_WORDS, \n",
    "                         EMBED_SIZE, \n",
    "                         input_length=MAX_ART_LEN, name='embed')(input_holder)\n",
    "\n",
    "            \n",
    "for arch in archs:\n",
    "    for dropout in dropout_rates:\n",
    "        for latent_dim in latent_dims:\n",
    "            func = eval(arch)\n",
    "            rnn_cell = func(latent_dim, dropout=dropout, recurrent_dropout=dropout, name=arch)(shared_embed)\n",
    "            hidden = Dense(20, activation='relu', name='hidden')(rnn_cell)\n",
    "            out = Dense(NUM_CLASSES, activation='relu', name='out')(hidden)\n",
    "\n",
    "            rnn=Model(inputs=input_holder, outputs=out)\n",
    "            rnn.compile(loss='categorical_crossentropy', \n",
    "                          optimizer='rmsprop', \n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            print('******', arch, ':', dropout, ',', latent_dim, '********')\n",
    "            print(rnn.summary())\n",
    "            rnns.append((rnn, (arch, dropout, latent_dim)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rnns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_ohe, test_size=0.2, stratify=y_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "fitting  ('LSTM', 0.0, 10)\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "4000/4000 [==============================] - 66s - loss: 3.4889 - acc: 0.5038 - val_loss: 3.2418 - val_acc: 0.6530\n",
      "Epoch 2/3\n",
      "4000/4000 [==============================] - 56s - loss: 3.1725 - acc: 0.6530 - val_loss: 3.1888 - val_acc: 0.6530\n",
      "Epoch 3/3\n",
      "4000/4000 [==============================] - 55s - loss: 3.1717 - acc: 0.6530 - val_loss: 3.1681 - val_acc: 0.6530\n",
      "\n",
      "\n",
      "fitting  ('LSTM', 0.0, 20)\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "4000/4000 [==============================] - 73s - loss: 1.1421 - acc: 0.5567 - val_loss: 1.0413 - val_acc: 0.6530\n",
      "Epoch 2/3\n",
      "4000/4000 [==============================] - 72s - loss: 1.0288 - acc: 0.6530 - val_loss: 1.0347 - val_acc: 0.6530\n",
      "Epoch 3/3\n",
      "4000/4000 [==============================] - 72s - loss: 1.0457 - acc: 0.6530 - val_loss: 1.0252 - val_acc: 0.6530\n",
      "\n",
      "\n",
      "fitting  ('LSTM', 0.0, 30)\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "4000/4000 [==============================] - 170s - loss: 5.3436 - acc: 0.6388 - val_loss: 5.2326 - val_acc: 0.6530\n",
      "Epoch 2/3\n",
      "4000/4000 [==============================] - 55s - loss: 5.1666 - acc: 0.6530 - val_loss: 5.1959 - val_acc: 0.6530\n",
      "Epoch 3/3\n",
      "4000/4000 [==============================] - 50s - loss: 5.1662 - acc: 0.6530 - val_loss: 5.2067 - val_acc: 0.6530\n",
      "\n",
      "\n",
      "fitting  ('LSTM', 0.2, 10)\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "4000/4000 [==============================] - 46s - loss: 13.2947 - acc: 0.1492 - val_loss: 13.3013 - val_acc: 0.1490\n",
      "Epoch 2/3\n",
      "4000/4000 [==============================] - 56s - loss: 13.2900 - acc: 0.1492 - val_loss: 13.2961 - val_acc: 0.1490\n",
      "Epoch 3/3\n",
      "4000/4000 [==============================] - 42s - loss: 13.2831 - acc: 0.1493 - val_loss: 13.3202 - val_acc: 0.1490\n",
      "\n",
      "\n",
      "fitting  ('LSTM', 0.2, 20)\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "4000/4000 [==============================] - 53s - loss: 3.3904 - acc: 0.6530 - val_loss: 3.3873 - val_acc: 0.6530\n",
      "Epoch 2/3\n",
      "4000/4000 [==============================] - 51s - loss: 3.3779 - acc: 0.6530 - val_loss: 3.3906 - val_acc: 0.6530\n",
      "Epoch 3/3\n",
      "4000/4000 [==============================] - 51s - loss: 3.3662 - acc: 0.6530 - val_loss: 3.3877 - val_acc: 0.6530\n",
      "\n",
      "\n",
      "fitting  ('LSTM', 0.2, 30)\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "4000/4000 [==============================] - 61s - loss: 10.9932 - acc: 0.1218 - val_loss: 10.9465 - val_acc: 0.1620\n",
      "Epoch 2/3\n",
      "4000/4000 [==============================] - 63s - loss: 10.9184 - acc: 0.1720 - val_loss: 10.9183 - val_acc: 0.1620\n",
      "Epoch 3/3\n",
      "4000/4000 [==============================] - 59s - loss: 10.9099 - acc: 0.1708 - val_loss: 10.9423 - val_acc: 0.1620\n",
      "\n",
      "\n",
      "fitting  ('LSTM', 0.6, 10)\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "4000/4000 [==============================] - 43s - loss: 13.5110 - acc: 0.1617 - val_loss: 13.5070 - val_acc: 0.1620\n",
      "Epoch 2/3\n",
      "4000/4000 [==============================] - 42s - loss: 13.5110 - acc: 0.1618 - val_loss: 13.5070 - val_acc: 0.1620\n",
      "Epoch 3/3\n",
      "4000/4000 [==============================] - 42s - loss: 13.5110 - acc: 0.1618 - val_loss: 13.5070 - val_acc: 0.1620\n",
      "\n",
      "\n",
      "fitting  ('LSTM', 0.6, 20)\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "4000/4000 [==============================] - 50s - loss: 7.0979 - acc: 0.1285 - val_loss: 3.4847 - val_acc: 0.1620\n",
      "Epoch 2/3\n",
      "4000/4000 [==============================] - 48s - loss: 3.2187 - acc: 0.4350 - val_loss: 3.0426 - val_acc: 0.6530\n",
      "Epoch 3/3\n",
      "4000/4000 [==============================] - 50s - loss: 3.0446 - acc: 0.6530 - val_loss: 3.2557 - val_acc: 0.6530\n",
      "\n",
      "\n",
      "fitting  ('LSTM', 0.6, 30)\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "4000/4000 [==============================] - 61s - loss: 3.3882 - acc: 0.5440 - val_loss: 3.5351 - val_acc: 0.6530\n",
      "Epoch 2/3\n",
      "4000/4000 [==============================] - 60s - loss: 3.2078 - acc: 0.6530 - val_loss: 3.2239 - val_acc: 0.6530\n",
      "Epoch 3/3\n",
      "4000/4000 [==============================] - 62s - loss: 3.2070 - acc: 0.6530 - val_loss: 3.4765 - val_acc: 0.6530\n",
      "\n",
      "\n",
      "fitting  ('GRU', 0.0, 10)\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "4000/4000 [==============================] - 26s - loss: 2.7873 - acc: 0.6530 - val_loss: 1.4516 - val_acc: 0.6530\n",
      "Epoch 2/3\n",
      "4000/4000 [==============================] - 26s - loss: 1.3661 - acc: 0.6530 - val_loss: 1.3691 - val_acc: 0.6530\n",
      "Epoch 3/3\n",
      "4000/4000 [==============================] - 27s - loss: 1.3622 - acc: 0.6530 - val_loss: 1.3518 - val_acc: 0.6530\n",
      "\n",
      "\n",
      "fitting  ('GRU', 0.0, 20)\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "4000/4000 [==============================] - 34s - loss: 3.3847 - acc: 0.6530 - val_loss: 3.3919 - val_acc: 0.6530\n",
      "Epoch 2/3\n",
      "4000/4000 [==============================] - 33s - loss: 3.3531 - acc: 0.6530 - val_loss: 3.4310 - val_acc: 0.6530\n",
      "Epoch 3/3\n",
      "4000/4000 [==============================] - 31s - loss: 3.3458 - acc: 0.6560 - val_loss: 3.5968 - val_acc: 0.6560\n",
      "\n",
      "\n",
      "fitting  ('GRU', 0.0, 30)\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "4000/4000 [==============================] - 40s - loss: 5.5930 - acc: 0.6530 - val_loss: 5.5930 - val_acc: 0.6530\n",
      "Epoch 2/3\n",
      "4000/4000 [==============================] - 41s - loss: 5.5930 - acc: 0.6530 - val_loss: 5.5930 - val_acc: 0.6530\n",
      "Epoch 3/3\n",
      "4000/4000 [==============================] - 44s - loss: 5.5930 - acc: 0.6530 - val_loss: 5.5930 - val_acc: 0.6530\n",
      "\n",
      "\n",
      "fitting  ('GRU', 0.2, 10)\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "4000/4000 [==============================] - 36s - loss: 10.9270 - acc: 0.1458 - val_loss: 10.8678 - val_acc: 0.1620\n",
      "Epoch 2/3\n",
      "4000/4000 [==============================] - 32s - loss: 10.8795 - acc: 0.1647 - val_loss: 10.8650 - val_acc: 0.1720\n",
      "Epoch 3/3\n",
      "4000/4000 [==============================] - 33s - loss: 10.9020 - acc: 0.1805 - val_loss: 10.9085 - val_acc: 0.1710\n",
      "\n",
      "\n",
      "fitting  ('GRU', 0.2, 20)\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "4000/4000 [==============================] - 40s - loss: 13.7115 - acc: 0.1492 - val_loss: 13.7165 - val_acc: 0.1490\n",
      "Epoch 2/3\n",
      "4000/4000 [==============================] - 41s - loss: 13.7096 - acc: 0.1493 - val_loss: 13.7074 - val_acc: 0.1490\n",
      "Epoch 3/3\n",
      "4000/4000 [==============================] - 43s - loss: 13.7059 - acc: 0.1493 - val_loss: 13.7165 - val_acc: 0.1490\n",
      "\n",
      "\n",
      "fitting  ('GRU', 0.2, 30)\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "4000/4000 [==============================] - 49s - loss: 3.6135 - acc: 0.4733 - val_loss: 3.3908 - val_acc: 0.6530\n",
      "Epoch 2/3\n",
      "4000/4000 [==============================] - 47s - loss: 3.3947 - acc: 0.6530 - val_loss: 3.3883 - val_acc: 0.6530\n",
      "Epoch 3/3\n",
      "4000/4000 [==============================] - 48s - loss: 3.3867 - acc: 0.6530 - val_loss: 3.3895 - val_acc: 0.6530\n",
      "\n",
      "\n",
      "fitting  ('GRU', 0.6, 10)\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "4000/4000 [==============================] - 34s - loss: 3.7866 - acc: 0.4155 - val_loss: 3.4118 - val_acc: 0.6530\n",
      "Epoch 2/3\n",
      "4000/4000 [==============================] - 33s - loss: 3.4648 - acc: 0.6403 - val_loss: 3.3950 - val_acc: 0.6530\n",
      "Epoch 3/3\n",
      "4000/4000 [==============================] - 34s - loss: 3.4005 - acc: 0.6523 - val_loss: 3.3977 - val_acc: 0.6530\n",
      "\n",
      "\n",
      "fitting  ('GRU', 0.6, 20)\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "4000/4000 [==============================] - 40s - loss: 13.5110 - acc: 0.1618 - val_loss: 13.5070 - val_acc: 0.1620\n",
      "Epoch 2/3\n",
      "4000/4000 [==============================] - 41s - loss: 13.5110 - acc: 0.1618 - val_loss: 13.5070 - val_acc: 0.1620\n",
      "Epoch 3/3\n",
      "4000/4000 [==============================] - 41s - loss: 13.5110 - acc: 0.1618 - val_loss: 13.5070 - val_acc: 0.1620\n",
      "\n",
      "\n",
      "fitting  ('GRU', 0.6, 30)\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "4000/4000 [==============================] - 51s - loss: 14.5257 - acc: 0.0052 - val_loss: 13.1722 - val_acc: 0.0050\n",
      "Epoch 2/3\n",
      "4000/4000 [==============================] - 50s - loss: 13.1147 - acc: 0.1310 - val_loss: 13.0974 - val_acc: 0.1620\n",
      "Epoch 3/3\n",
      "4000/4000 [==============================] - 52s - loss: 13.1123 - acc: 0.1618 - val_loss: 13.0933 - val_acc: 0.1620\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as mt\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for rnn in rnns:\n",
    "    print('\\n\\nfitting ', rnn[1])\n",
    "    rnn[0].fit(X_train, y_train, batch_size=100, epochs=3, validation_data=[X_test, y_test])\n",
    "    \n",
    "    yhat = np.round(rnn[0].predict(X_test))\n",
    "    acc = mt.accuracy_score(yhat, y_test)\n",
    "    accuracies.append((acc, rnn[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_0.0_10.h5\n",
      "LSTM_0.0_20.h5\n",
      "LSTM_0.0_30.h5\n",
      "LSTM_0.2_10.h5\n",
      "LSTM_0.2_20.h5\n",
      "LSTM_0.2_30.h5\n",
      "LSTM_0.6_10.h5\n",
      "LSTM_0.6_20.h5\n",
      "LSTM_0.6_30.h5\n",
      "GRU_0.0_10.h5\n",
      "GRU_0.0_20.h5\n",
      "GRU_0.0_30.h5\n",
      "GRU_0.2_10.h5\n",
      "GRU_0.2_20.h5\n",
      "GRU_0.2_30.h5\n",
      "GRU_0.6_10.h5\n",
      "GRU_0.6_20.h5\n",
      "GRU_0.6_30.h5\n"
     ]
    }
   ],
   "source": [
    "for rnn in rnns:\n",
    "    name = rnn[1][0]+'_'+str(rnn[1][1])+'_'+str(rnn[1][2])+'.h5'\n",
    "    print(name)\n",
    "    rnn[0].save('./models/'+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = rnn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_layer = model.get_layer('embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = embed_layer.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'of': 2,\n",
       " 'and': 3,\n",
       " 'a': 4,\n",
       " 'to': 5,\n",
       " 'in': 6,\n",
       " 'that': 7,\n",
       " 'is': 8,\n",
       " 'on': 9,\n",
       " 'with': 10,\n",
       " 'as': 11,\n",
       " 'it': 12,\n",
       " 'for': 13,\n",
       " 'but': 14,\n",
       " 'his': 15,\n",
       " 'like': 16,\n",
       " 'from': 17,\n",
       " 'an': 18,\n",
       " 'this': 19,\n",
       " 'their': 20,\n",
       " 'you': 21,\n",
       " 'are': 22,\n",
       " 'more': 23,\n",
       " 'at': 24,\n",
       " 'by': 25,\n",
       " 'be': 26,\n",
       " \"it's\": 27,\n",
       " 'or': 28,\n",
       " 'he': 29,\n",
       " 'its': 30,\n",
       " 'i': 31,\n",
       " 'album': 32,\n",
       " 'out': 33,\n",
       " 'all': 34,\n",
       " 'one': 35,\n",
       " 'not': 36,\n",
       " 'into': 37,\n",
       " 'they': 38,\n",
       " 'music': 39,\n",
       " 'was': 40,\n",
       " 'up': 41,\n",
       " 'have': 42,\n",
       " 'has': 43,\n",
       " 'than': 44,\n",
       " 'so': 45,\n",
       " 'songs': 46,\n",
       " 'most': 47,\n",
       " 'which': 48,\n",
       " '\\r': 49,\n",
       " 'if': 50,\n",
       " 'just': 51,\n",
       " 'when': 52,\n",
       " 'band': 53,\n",
       " 'even': 54,\n",
       " 'about': 55,\n",
       " 'sound': 56,\n",
       " 'song': 57,\n",
       " 'some': 58,\n",
       " 'what': 59,\n",
       " 'new': 60,\n",
       " 'can': 61,\n",
       " 'time': 62,\n",
       " 'her': 63,\n",
       " 'rock': 64,\n",
       " 'no': 65,\n",
       " 'these': 66,\n",
       " 'first': 67,\n",
       " 'record': 68,\n",
       " 'over': 69,\n",
       " 'much': 70,\n",
       " 'while': 71,\n",
       " 'here': 72,\n",
       " 'guitar': 73,\n",
       " 'who': 74,\n",
       " 'two': 75,\n",
       " 'only': 76,\n",
       " 'track': 77,\n",
       " 'pop': 78,\n",
       " 'been': 79,\n",
       " 'sounds': 80,\n",
       " 'tracks': 81,\n",
       " 'way': 82,\n",
       " 'there': 83,\n",
       " 'them': 84,\n",
       " 'my': 85,\n",
       " 'still': 86,\n",
       " 'your': 87,\n",
       " 'through': 88,\n",
       " 'off': 89,\n",
       " 'also': 90,\n",
       " 'were': 91,\n",
       " 'too': 92,\n",
       " 'though': 93,\n",
       " 'where': 94,\n",
       " 'me': 95,\n",
       " 'other': 96,\n",
       " 'best': 97,\n",
       " 'could': 98,\n",
       " 'well': 99,\n",
       " 'back': 100,\n",
       " 'work': 101,\n",
       " 'between': 102,\n",
       " 'own': 103,\n",
       " 'get': 104,\n",
       " 'would': 105,\n",
       " 'how': 106,\n",
       " 'after': 107,\n",
       " 'make': 108,\n",
       " 'love': 109,\n",
       " 'never': 110,\n",
       " 'years': 111,\n",
       " 'something': 112,\n",
       " 'those': 113,\n",
       " 'little': 114,\n",
       " 'we': 115,\n",
       " 'down': 116,\n",
       " 'any': 117,\n",
       " 'good': 118,\n",
       " \"there's\": 119,\n",
       " 'do': 120,\n",
       " 'now': 121,\n",
       " 'had': 122,\n",
       " 'she': 123,\n",
       " 'might': 124,\n",
       " 'few': 125,\n",
       " 'then': 126,\n",
       " 'before': 127,\n",
       " 'last': 128,\n",
       " 'same': 129,\n",
       " 'will': 130,\n",
       " 'both': 131,\n",
       " \"that's\": 132,\n",
       " \"he's\": 133,\n",
       " 'long': 134,\n",
       " 'voice': 135,\n",
       " 'around': 136,\n",
       " \"don't\": 137,\n",
       " 'many': 138,\n",
       " 'made': 139,\n",
       " 'him': 140,\n",
       " 'vocals': 141,\n",
       " 'makes': 142,\n",
       " 'every': 143,\n",
       " 'less': 144,\n",
       " 'world': 145,\n",
       " '”': 146,\n",
       " 'such': 147,\n",
       " 'enough': 148,\n",
       " 'full': 149,\n",
       " 'often': 150,\n",
       " 'take': 151,\n",
       " 'another': 152,\n",
       " 'feel': 153,\n",
       " 'three': 154,\n",
       " 'almost': 155,\n",
       " 'it’s': 156,\n",
       " 'being': 157,\n",
       " 'without': 158,\n",
       " 'come': 159,\n",
       " 'seems': 160,\n",
       " 'because': 161,\n",
       " 'sense': 162,\n",
       " 'yet': 163,\n",
       " 'lyrics': 164,\n",
       " 'old': 165,\n",
       " \"band's\": 166,\n",
       " 'always': 167,\n",
       " 'albums': 168,\n",
       " 'live': 169,\n",
       " 'end': 170,\n",
       " 'self': 171,\n",
       " 'year': 172,\n",
       " 'kind': 173,\n",
       " 'debut': 174,\n",
       " 'title': 175,\n",
       " \"doesn't\": 176,\n",
       " 'early': 177,\n",
       " 'ever': 178,\n",
       " 'life': 179,\n",
       " 'records': 180,\n",
       " 'really': 181,\n",
       " 'hard': 182,\n",
       " 'know': 183,\n",
       " 'very': 184,\n",
       " 'go': 185,\n",
       " 'part': 186,\n",
       " 'since': 187,\n",
       " 'point': 188,\n",
       " 'thing': 189,\n",
       " 'each': 190,\n",
       " 'half': 191,\n",
       " 'set': 192,\n",
       " 'bass': 193,\n",
       " 'feels': 194,\n",
       " 'people': 195,\n",
       " 'may': 196,\n",
       " 'does': 197,\n",
       " 'black': 198,\n",
       " 'great': 199,\n",
       " \"they're\": 200,\n",
       " \"i'm\": 201,\n",
       " 'better': 202,\n",
       " 'second': 203,\n",
       " 'right': 204,\n",
       " 'things': 205,\n",
       " 'vocal': 206,\n",
       " 'release': 207,\n",
       " 'bit': 208,\n",
       " 'minutes': 209,\n",
       " 'far': 210,\n",
       " 'comes': 211,\n",
       " 'big': 212,\n",
       " 'together': 213,\n",
       " 'rather': 214,\n",
       " 'indie': 215,\n",
       " 'single': 216,\n",
       " 'say': 217,\n",
       " 'four': 218,\n",
       " \"album's\": 219,\n",
       " 'got': 220,\n",
       " 'line': 221,\n",
       " 'hear': 222,\n",
       " 'past': 223,\n",
       " 'punk': 224,\n",
       " 'least': 225,\n",
       " 'high': 226,\n",
       " 'piano': 227,\n",
       " 'man': 228,\n",
       " \"isn't\": 229,\n",
       " 'style': 230,\n",
       " 'moments': 231,\n",
       " 'once': 232,\n",
       " 'beat': 233,\n",
       " 'minute': 234,\n",
       " 'dance': 235,\n",
       " 'solo': 236,\n",
       " 'us': 237,\n",
       " 'released': 238,\n",
       " 'name': 239,\n",
       " 'again': 240,\n",
       " 'see': 241,\n",
       " 'seem': 242,\n",
       " 'post': 243,\n",
       " 'group': 244,\n",
       " 'nothing': 245,\n",
       " 'instead': 246,\n",
       " 'away': 247,\n",
       " 'bands': 248,\n",
       " 'place': 249,\n",
       " 'guitars': 250,\n",
       " 'house': 251,\n",
       " 'label': 252,\n",
       " 'making': 253,\n",
       " 'production': 254,\n",
       " 'musical': 255,\n",
       " 'lot': 256,\n",
       " 'pretty': 257,\n",
       " 'recorded': 258,\n",
       " 'actually': 259,\n",
       " 'metal': 260,\n",
       " 'drums': 261,\n",
       " 'think': 262,\n",
       " 'melody': 263,\n",
       " 'anything': 264,\n",
       " 'material': 265,\n",
       " 'going': 266,\n",
       " 'b': 267,\n",
       " \"you're\": 268,\n",
       " 'course': 269,\n",
       " 'drum': 270,\n",
       " 'along': 271,\n",
       " 'beats': 272,\n",
       " 'noise': 273,\n",
       " 'acoustic': 274,\n",
       " 'singer': 275,\n",
       " \"can't\": 276,\n",
       " 'fact': 277,\n",
       " 'playing': 278,\n",
       " 'side': 279,\n",
       " 'want': 280,\n",
       " 'find': 281,\n",
       " 'himself': 282,\n",
       " 'moment': 283,\n",
       " 'day': 284,\n",
       " 'times': 285,\n",
       " 'sort': 286,\n",
       " 'different': 287,\n",
       " 'ep': 288,\n",
       " 'next': 289,\n",
       " 'quite': 290,\n",
       " 'mind': 291,\n",
       " 'under': 292,\n",
       " 'everything': 293,\n",
       " 'cover': 294,\n",
       " 'itself': 295,\n",
       " 'should': 296,\n",
       " 'young': 297,\n",
       " 'sometimes': 298,\n",
       " 'space': 299,\n",
       " 'career': 300,\n",
       " 'synth': 301,\n",
       " 'hip': 302,\n",
       " 'chorus': 303,\n",
       " 'perhaps': 304,\n",
       " 'folk': 305,\n",
       " 'version': 306,\n",
       " 'real': 307,\n",
       " 'play': 308,\n",
       " 'mix': 309,\n",
       " 'our': 310,\n",
       " 'sings': 311,\n",
       " 'takes': 312,\n",
       " 'whole': 313,\n",
       " 'easy': 314,\n",
       " 'hop': 315,\n",
       " 'light': 316,\n",
       " 'soul': 317,\n",
       " 'home': 318,\n",
       " 'probably': 319,\n",
       " 'electronic': 320,\n",
       " 'why': 321,\n",
       " 'later': 322,\n",
       " 'lines': 323,\n",
       " 'late': 324,\n",
       " 'show': 325,\n",
       " 'maybe': 326,\n",
       " 'rap': 327,\n",
       " 'original': 328,\n",
       " 'themselves': 329,\n",
       " 'slow': 330,\n",
       " 'left': 331,\n",
       " 'put': 332,\n",
       " 'studio': 333,\n",
       " 'despite': 334,\n",
       " 'heavy': 335,\n",
       " 'during': 336,\n",
       " 'fans': 337,\n",
       " 'disc': 338,\n",
       " 'death': 339,\n",
       " 'already': 340,\n",
       " 'mostly': 341,\n",
       " 'melodies': 342,\n",
       " 'against': 343,\n",
       " 'lost': 344,\n",
       " 'whose': 345,\n",
       " 'however': 346,\n",
       " 'jazz': 347,\n",
       " 'found': 348,\n",
       " 'heard': 349,\n",
       " 'art': 350,\n",
       " 'piece': 351,\n",
       " 'gets': 352,\n",
       " 'power': 353,\n",
       " 'especially': 354,\n",
       " 'either': 355,\n",
       " 'words': 356,\n",
       " 'r': 357,\n",
       " 'night': 358,\n",
       " 'until': 359,\n",
       " 'did': 360,\n",
       " 'collection': 361,\n",
       " 'instrumental': 362,\n",
       " 'listening': 363,\n",
       " 'artists': 364,\n",
       " 'five': 365,\n",
       " 'listen': 366,\n",
       " 'form': 367,\n",
       " 'opening': 368,\n",
       " 'singing': 369,\n",
       " 'need': 370,\n",
       " 'given': 371,\n",
       " 'behind': 372,\n",
       " 'become': 373,\n",
       " 'funk': 374,\n",
       " 'recent': 375,\n",
       " 'the\\r': 376,\n",
       " 'heart': 377,\n",
       " 'length': 378,\n",
       " 'approach': 379,\n",
       " 'days': 380,\n",
       " 'classic': 381,\n",
       " 'works': 382,\n",
       " 'rhythm': 383,\n",
       " 'producer': 384,\n",
       " 'free': 385,\n",
       " 'head': 386,\n",
       " 'dark': 387,\n",
       " 'bad': 388,\n",
       " 'turn': 389,\n",
       " 'trying': 390,\n",
       " 'closer': 391,\n",
       " 'project': 392,\n",
       " 'give': 393,\n",
       " 'recording': 394,\n",
       " 'hand': 395,\n",
       " 'city': 396,\n",
       " 'keep': 397,\n",
       " 'cut': 398,\n",
       " 'simple': 399,\n",
       " 'nearly': 400,\n",
       " 'country': 401,\n",
       " 'opener': 402,\n",
       " 'sonic': 403,\n",
       " 'white': 404,\n",
       " 'called': 405,\n",
       " 'deep': 406,\n",
       " 'across': 407,\n",
       " 'hit': 408,\n",
       " 'said': 409,\n",
       " 'goes': 410,\n",
       " 'dead': 411,\n",
       " 'room': 412,\n",
       " 'interesting': 413,\n",
       " 'radio': 414,\n",
       " 'american': 415,\n",
       " \"they've\": 416,\n",
       " 'close': 417,\n",
       " 'notes': 418,\n",
       " 'simply': 419,\n",
       " 'let': 420,\n",
       " 'low': 421,\n",
       " 'clear': 422,\n",
       " 'artist': 423,\n",
       " 'throughout': 424,\n",
       " 'short': 425,\n",
       " 'era': 426,\n",
       " 'percussion': 427,\n",
       " 'sure': 428,\n",
       " 'true': 429,\n",
       " 'sounding': 430,\n",
       " 'scene': 431,\n",
       " 'else': 432,\n",
       " 'lead': 433,\n",
       " 'genre': 434,\n",
       " 'someone': 435,\n",
       " 'came': 436,\n",
       " 'perfect': 437,\n",
       " 'six': 438,\n",
       " 'john': 439,\n",
       " 'feeling': 440,\n",
       " 'future': 441,\n",
       " 'rest': 442,\n",
       " 'whether': 443,\n",
       " 'look': 444,\n",
       " 'lp': 445,\n",
       " 'disco': 446,\n",
       " 'decade': 447,\n",
       " 'strings': 448,\n",
       " 'mid': 449,\n",
       " 'fun': 450,\n",
       " 'call': 451,\n",
       " 'start': 452,\n",
       " \"didn't\": 453,\n",
       " 'blues': 454,\n",
       " 'shows': 455,\n",
       " 'run': 456,\n",
       " 'anyone': 457,\n",
       " 'within': 458,\n",
       " 'similar': 459,\n",
       " 'stuff': 460,\n",
       " 'played': 461,\n",
       " 'third': 462,\n",
       " 'idea': 463,\n",
       " 'tone': 464,\n",
       " 'open': 465,\n",
       " 'couple': 466,\n",
       " 'getting': 467,\n",
       " 'familiar': 468,\n",
       " 'girl': 469,\n",
       " 'exactly': 470,\n",
       " 'based': 471,\n",
       " 'used': 472,\n",
       " 'turns': 473,\n",
       " 'finds': 474,\n",
       " 'case': 475,\n",
       " 'matter': 476,\n",
       " 'quality': 477,\n",
       " 'doing': 478,\n",
       " 'certainly': 479,\n",
       " 'working': 480,\n",
       " 'age': 481,\n",
       " 'toward': 482,\n",
       " 'synths': 483,\n",
       " 'hits': 484,\n",
       " 'known': 485,\n",
       " 'coming': 486,\n",
       " 'songwriting': 487,\n",
       " 'attention': 488,\n",
       " 'word': 489,\n",
       " 'ideas': 490,\n",
       " 'small': 491,\n",
       " 'top': 492,\n",
       " 'melodic': 493,\n",
       " 'story': 494,\n",
       " 'series': 495,\n",
       " 'fire': 496,\n",
       " 'arrangements': 497,\n",
       " 'previous': 498,\n",
       " 'pieces': 499,\n",
       " 'further': 500,\n",
       " 'former': 501,\n",
       " 'final': 502,\n",
       " 'taking': 503,\n",
       " 'guitarist': 504,\n",
       " 'use': 505,\n",
       " 'particularly': 506,\n",
       " 'number': 507,\n",
       " 'help': 508,\n",
       " 'musicians': 509,\n",
       " 'electric': 510,\n",
       " 'plays': 511,\n",
       " 'club': 512,\n",
       " 'history': 513,\n",
       " 'produced': 514,\n",
       " '2': 515,\n",
       " 'modern': 516,\n",
       " 'dj': 517,\n",
       " 'recordings': 518,\n",
       " 'beyond': 519,\n",
       " 'finally': 520,\n",
       " 'features': 521,\n",
       " 'rhythms': 522,\n",
       " 'change': 523,\n",
       " 'ways': 524,\n",
       " 'note': 525,\n",
       " 'drummer': 526,\n",
       " 'energy': 527,\n",
       " 'groove': 528,\n",
       " 'riff': 529,\n",
       " 'straight': 530,\n",
       " 'alone': 531,\n",
       " \"aren't\": 532,\n",
       " 'tell': 533,\n",
       " 'string': 534,\n",
       " 'middle': 535,\n",
       " 'occasionally': 536,\n",
       " 'singles': 537,\n",
       " 'parts': 538,\n",
       " 'ambient': 539,\n",
       " 'titled': 540,\n",
       " 'guy': 541,\n",
       " 'soundtrack': 542,\n",
       " 'break': 543,\n",
       " 'sing': 544,\n",
       " 'emotional': 545,\n",
       " 'star': 546,\n",
       " 'strong': 547,\n",
       " 'fall': 548,\n",
       " 'ends': 549,\n",
       " 'likely': 550,\n",
       " 'built': 551,\n",
       " 'move': 552,\n",
       " 'done': 553,\n",
       " \"she's\": 554,\n",
       " 'follow': 555,\n",
       " 'among': 556,\n",
       " 'elements': 557,\n",
       " 'inspired': 558,\n",
       " 'mark': 559,\n",
       " 'effect': 560,\n",
       " 'gives': 561,\n",
       " 'slightly': 562,\n",
       " 'techno': 563,\n",
       " 'party': 564,\n",
       " 'several': 565,\n",
       " 'air': 566,\n",
       " 'duo': 567,\n",
       " 'machine': 568,\n",
       " 'listeners': 569,\n",
       " 'focus': 570,\n",
       " 'hooks': 571,\n",
       " 'easily': 572,\n",
       " 'upon': 573,\n",
       " 'gone': 574,\n",
       " '10': 575,\n",
       " \"i've\": 576,\n",
       " 'he’s': 577,\n",
       " 'verse': 578,\n",
       " 'seven': 579,\n",
       " 'boy': 580,\n",
       " 'tune': 581,\n",
       " 'aesthetic': 582,\n",
       " 'releases': 583,\n",
       " 'dream': 584,\n",
       " 'voices': 585,\n",
       " 'mood': 586,\n",
       " 'certain': 587,\n",
       " 'personal': 588,\n",
       " 'school': 589,\n",
       " 'obvious': 590,\n",
       " 'opens': 591,\n",
       " 'near': 592,\n",
       " 'others': 593,\n",
       " '1': 594,\n",
       " 'range': 595,\n",
       " 'soft': 596,\n",
       " 'seemed': 597,\n",
       " 'audience': 598,\n",
       " 'act': 599,\n",
       " 'strange': 600,\n",
       " 'imagine': 601,\n",
       " 'ultimately': 602,\n",
       " 'means': 603,\n",
       " 'major': 604,\n",
       " 'level': 605,\n",
       " 'worth': 606,\n",
       " 'tape': 607,\n",
       " 'having': 608,\n",
       " 'lack': 609,\n",
       " 'sun': 610,\n",
       " 'chords': 611,\n",
       " 'earlier': 612,\n",
       " 'ago': 613,\n",
       " 'hook': 614,\n",
       " 'wave': 615,\n",
       " 'am': 616,\n",
       " 'remains': 617,\n",
       " 'particular': 618,\n",
       " 'result': 619,\n",
       " 's': 620,\n",
       " 'outside': 621,\n",
       " 'key': 622,\n",
       " 'face': 623,\n",
       " 'shit': 624,\n",
       " 'there’s': 625,\n",
       " 'begins': 626,\n",
       " 'organ': 627,\n",
       " 'riffs': 628,\n",
       " 'including': 629,\n",
       " 'theme': 630,\n",
       " 'human': 631,\n",
       " 'harmonies': 632,\n",
       " 'plenty': 633,\n",
       " 'york': 634,\n",
       " 'electro': 635,\n",
       " 'latter': 636,\n",
       " 'members': 637,\n",
       " 'taken': 638,\n",
       " 'friends': 639,\n",
       " 'influences': 640,\n",
       " 'eyes': 641,\n",
       " 'fine': 642,\n",
       " 'fi': 643,\n",
       " 'e': 644,\n",
       " 'blue': 645,\n",
       " 'double': 646,\n",
       " 'looking': 647,\n",
       " 'entirely': 648,\n",
       " 'above': 649,\n",
       " 'lyrical': 650,\n",
       " 'underground': 651,\n",
       " 'section': 652,\n",
       " 'experience': 653,\n",
       " 'instruments': 654,\n",
       " 'fuck': 655,\n",
       " 'completely': 656,\n",
       " 'although': 657,\n",
       " 'film': 658,\n",
       " 'hardcore': 659,\n",
       " 'stand': 660,\n",
       " 'red': 661,\n",
       " 'cool': 662,\n",
       " 'writing': 663,\n",
       " 'sweet': 664,\n",
       " 'felt': 665,\n",
       " 'beautiful': 666,\n",
       " 'remix': 667,\n",
       " 'otherwise': 668,\n",
       " 'subtle': 669,\n",
       " 'performance': 670,\n",
       " 'fit': 671,\n",
       " 'acts': 672,\n",
       " \"what's\": 673,\n",
       " 'thought': 674,\n",
       " 'compilation': 675,\n",
       " 'hell': 676,\n",
       " 'took': 677,\n",
       " 'ballad': 678,\n",
       " 'that’s': 679,\n",
       " 'stop': 680,\n",
       " 'talk': 681,\n",
       " 'weird': 682,\n",
       " 'background': 683,\n",
       " 'songwriter': 684,\n",
       " 'following': 685,\n",
       " 'went': 686,\n",
       " 'reason': 687,\n",
       " \"we're\": 688,\n",
       " 'guys': 689,\n",
       " 'example': 690,\n",
       " 'kids': 691,\n",
       " 'tones': 692,\n",
       " 'cuts': 693,\n",
       " 'step': 694,\n",
       " 'written': 695,\n",
       " 'david': 696,\n",
       " 'hands': 697,\n",
       " 'd': 698,\n",
       " 'success': 699,\n",
       " 'boys': 700,\n",
       " \"'s\": 701,\n",
       " 'o': 702,\n",
       " 'god': 703,\n",
       " 'perfectly': 704,\n",
       " 'entire': 705,\n",
       " 'non': 706,\n",
       " 'samples': 707,\n",
       " \"record's\": 708,\n",
       " \"you've\": 709,\n",
       " 'tunes': 710,\n",
       " 'ones': 711,\n",
       " '\\xa0': 712,\n",
       " 'difficult': 713,\n",
       " 'somewhere': 714,\n",
       " 'cd': 715,\n",
       " 'moving': 716,\n",
       " 'latest': 717,\n",
       " 'hot': 718,\n",
       " 'becomes': 719,\n",
       " 'offers': 720,\n",
       " 'summer': 721,\n",
       " 'jam': 722,\n",
       " 'return': 723,\n",
       " 'traditional': 724,\n",
       " 'forward': 725,\n",
       " 'inside': 726,\n",
       " 'sounded': 727,\n",
       " 'complete': 728,\n",
       " 'barely': 729,\n",
       " 'nice': 730,\n",
       " 'effects': 731,\n",
       " \"song's\": 732,\n",
       " 'listener': 733,\n",
       " 'garage': 734,\n",
       " 'context': 735,\n",
       " 'front': 736,\n",
       " 'stage': 737,\n",
       " 'clearly': 738,\n",
       " 'starts': 739,\n",
       " 'psychedelic': 740,\n",
       " 'longer': 741,\n",
       " 'hope': 742,\n",
       " 'drone': 743,\n",
       " 'whatever': 744,\n",
       " 'suggests': 745,\n",
       " 'baby': 746,\n",
       " 'tour': 747,\n",
       " 'mean': 748,\n",
       " 'brief': 749,\n",
       " 'try': 750,\n",
       " 'trio': 751,\n",
       " 'happy': 752,\n",
       " 're': 753,\n",
       " 'bring': 754,\n",
       " 'co': 755,\n",
       " 'largely': 756,\n",
       " 'everyone': 757,\n",
       " 'present': 758,\n",
       " 'points': 759,\n",
       " 'game': 760,\n",
       " 'box': 761,\n",
       " 'excellent': 762,\n",
       " '12': 763,\n",
       " '90s': 764,\n",
       " 'of\\r': 765,\n",
       " 'hour': 766,\n",
       " 'c': 767,\n",
       " 'solid': 768,\n",
       " 'rarely': 769,\n",
       " 'started': 770,\n",
       " 'usually': 771,\n",
       " 'create': 772,\n",
       " 'james': 773,\n",
       " 'broken': 774,\n",
       " 'living': 775,\n",
       " 'blood': 776,\n",
       " 'state': 777,\n",
       " 'u': 778,\n",
       " 'odd': 779,\n",
       " 'knows': 780,\n",
       " 'hold': 781,\n",
       " 'current': 782,\n",
       " 'quiet': 783,\n",
       " 't': 784,\n",
       " 'unlike': 785,\n",
       " 'ground': 786,\n",
       " 'fully': 787,\n",
       " 'la': 788,\n",
       " 'process': 789,\n",
       " 'important': 790,\n",
       " 'talking': 791,\n",
       " 'turned': 792,\n",
       " 'covers': 793,\n",
       " 'backing': 794,\n",
       " 'able': 795,\n",
       " 'keyboard': 796,\n",
       " 'quickly': 797,\n",
       " \"group's\": 798,\n",
       " 'concept': 799,\n",
       " 'wrong': 800,\n",
       " 'bright': 801,\n",
       " 'm': 802,\n",
       " 'cold': 803,\n",
       " 'stars': 804,\n",
       " 'spent': 805,\n",
       " \"you'll\": 806,\n",
       " 'verses': 807,\n",
       " 'greatest': 808,\n",
       " 'spirit': 809,\n",
       " 'street': 810,\n",
       " 'various': 811,\n",
       " 'eventually': 812,\n",
       " 'eight': 813,\n",
       " 'and\\r': 814,\n",
       " 'problem': 815,\n",
       " 'warm': 816,\n",
       " \"won't\": 817,\n",
       " 'proper': 818,\n",
       " 'sets': 819,\n",
       " 'wonder': 820,\n",
       " 'somehow': 821,\n",
       " 'possible': 822,\n",
       " 'leave': 823,\n",
       " 'british': 824,\n",
       " 'truly': 825,\n",
       " 'tempo': 826,\n",
       " 'rhythmic': 827,\n",
       " 'delivery': 828,\n",
       " 'effort': 829,\n",
       " 'expect': 830,\n",
       " 'roots': 831,\n",
       " \"year's\": 832,\n",
       " 'oh': 833,\n",
       " 'video': 834,\n",
       " 'digital': 835,\n",
       " 'rare': 836,\n",
       " 'culture': 837,\n",
       " 'wide': 838,\n",
       " 'somewhat': 839,\n",
       " 'build': 840,\n",
       " 'question': 841,\n",
       " 'became': 842,\n",
       " 'body': 843,\n",
       " 'money': 844,\n",
       " 'a\\r': 845,\n",
       " 'rich': 846,\n",
       " 'vocalist': 847,\n",
       " 'uk': 848,\n",
       " 'epic': 849,\n",
       " 'rapper': 850,\n",
       " 'don’t': 851,\n",
       " 'hearing': 852,\n",
       " 'order': 853,\n",
       " 'featuring': 854,\n",
       " 'influence': 855,\n",
       " 'king': 856,\n",
       " 'chance': 857,\n",
       " 'wild': 858,\n",
       " 'nature': 859,\n",
       " 'youth': 860,\n",
       " 'catchy': 861,\n",
       " 'tension': 862,\n",
       " 'similarly': 863,\n",
       " 'soon': 864,\n",
       " 'presence': 865,\n",
       " '20': 866,\n",
       " 'beginning': 867,\n",
       " 'unfortunately': 868,\n",
       " 'immediately': 869,\n",
       " 'towards': 870,\n",
       " 'center': 871,\n",
       " 'seen': 872,\n",
       " 'bassist': 873,\n",
       " 'sample': 874,\n",
       " 'told': 875,\n",
       " 'sad': 876,\n",
       " 'aside': 877,\n",
       " 'experimental': 878,\n",
       " 'sharp': 879,\n",
       " 'must': 880,\n",
       " 'war': 881,\n",
       " 'none': 882,\n",
       " 'write': 883,\n",
       " 'die': 884,\n",
       " 'lo': 885,\n",
       " 'beauty': 886,\n",
       " 'building': 887,\n",
       " 'potential': 888,\n",
       " 'loose': 889,\n",
       " \"wasn't\": 890,\n",
       " 'led': 891,\n",
       " 'moon': 892,\n",
       " 'dub': 893,\n",
       " 'collaboration': 894,\n",
       " 'born': 895,\n",
       " 'surprising': 896,\n",
       " 'girls': 897,\n",
       " 'field': 898,\n",
       " 'meant': 899,\n",
       " 'atmosphere': 900,\n",
       " 'guest': 901,\n",
       " 'driven': 902,\n",
       " 'brings': 903,\n",
       " 'unique': 904,\n",
       " 'producers': 905,\n",
       " 'yes': 906,\n",
       " 'remember': 907,\n",
       " 'figure': 908,\n",
       " 'century': 909,\n",
       " 'pure': 910,\n",
       " '80s': 911,\n",
       " 'using': 912,\n",
       " 'worked': 913,\n",
       " 'water': 914,\n",
       " 'add': 915,\n",
       " 'natural': 916,\n",
       " 'force': 917,\n",
       " 'kid': 918,\n",
       " 'date': 919,\n",
       " 'sex': 920,\n",
       " 'vision': 921,\n",
       " 'yourself': 922,\n",
       " \"i'd\": 923,\n",
       " 'terms': 924,\n",
       " 'elsewhere': 925,\n",
       " 'says': 926,\n",
       " 'west': 927,\n",
       " 'creative': 928,\n",
       " 'apart': 929,\n",
       " 'setting': 930,\n",
       " 'offer': 931,\n",
       " '4': 932,\n",
       " '3': 933,\n",
       " 'serious': 934,\n",
       " 'biggest': 935,\n",
       " 'giving': 936,\n",
       " \"you'd\": 937,\n",
       " 'touch': 938,\n",
       " 'psych': 939,\n",
       " 'surprisingly': 940,\n",
       " 'impressive': 941,\n",
       " 'period': 942,\n",
       " 'statement': 943,\n",
       " 'recently': 944,\n",
       " 'textures': 945,\n",
       " 'earth': 946,\n",
       " 'pull': 947,\n",
       " 'compelling': 948,\n",
       " 'running': 949,\n",
       " 'closing': 950,\n",
       " \"wouldn't\": 951,\n",
       " 'surprise': 952,\n",
       " 'actual': 953,\n",
       " 'flow': 954,\n",
       " 'believe': 955,\n",
       " 'favorite': 956,\n",
       " 'ready': 957,\n",
       " 'plus': 958,\n",
       " 'popular': 959,\n",
       " 'core': 960,\n",
       " 'raw': 961,\n",
       " 'keeps': 962,\n",
       " 'doesn’t': 963,\n",
       " 'onto': 964,\n",
       " \"i'll\": 965,\n",
       " 'compositions': 966,\n",
       " 'horns': 967,\n",
       " 'structure': 968,\n",
       " 'included': 969,\n",
       " 'family': 970,\n",
       " 'album’s': 971,\n",
       " 'months': 972,\n",
       " 'narrative': 973,\n",
       " 'member': 974,\n",
       " 'yeah': 975,\n",
       " 'results': 976,\n",
       " 'attempt': 977,\n",
       " 'direction': 978,\n",
       " 'today': 979,\n",
       " 'wrote': 980,\n",
       " 'de': 981,\n",
       " 'chord': 982,\n",
       " 'sky': 983,\n",
       " 'sea': 984,\n",
       " 'began': 985,\n",
       " 'loud': 986,\n",
       " 'large': 987,\n",
       " 'road': 988,\n",
       " 'suggest': 989,\n",
       " 'complex': 990,\n",
       " 'romantic': 991,\n",
       " 'deal': 992,\n",
       " 'moves': 993,\n",
       " 'catalog': 994,\n",
       " 'contrast': 995,\n",
       " 'frontman': 996,\n",
       " 'steady': 997,\n",
       " 'named': 998,\n",
       " 'indeed': 999,\n",
       " 'breaks': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkn.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 50)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_weights(w1, w2, w3, w4):\n",
    "    p1 = tkn.word_index[w1]\n",
    "    p2 = tkn.word_index[w2]\n",
    "    p3 = tkn.word_index[w3]\n",
    "    p4 = tkn.word_index[w4]\n",
    "\n",
    "    e1 = weights[p1]\n",
    "    e2 = weights[p2]\n",
    "    e3 = weights[p3]\n",
    "    e4 = weights[p4]\n",
    "\n",
    "    distance = np.abs(e1 - e2)\n",
    "\n",
    "    d1 = np.argmax(distance)\n",
    "    d2 = np.argmax(np.delete(distance, d1))\n",
    "\n",
    "    e1_2d = (e1[d1], e1[d2])\n",
    "    e2_2d = (e2[d1], e2[d2])\n",
    "    e3_2d = (e3[d1], e3[d2])\n",
    "    e4_2d = (e4[d1], e4[d2])\n",
    "\n",
    "    plt.scatter([e1_2d[0], e2_2d[0], e3_2d[0], e4_2d[0]],[e1_2d[1], e2_2d[1], e3_2d[1], e4_2d[1]])\n",
    "    plt.annotate(w1, e1_2d)\n",
    "    plt.annotate(w2, e2_2d)\n",
    "    plt.annotate(w3, e3_2d)\n",
    "    plt.annotate(w4, e4_2d)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAGL5JREFUeJzt3X+UVXX97/Hn+ztg0kUFQhHxi+iS\ni6n8yoGvlSLJr1Z4A75aLG/ZVF/EurpsdRdccZlm3lxRtJaldmkRZXzLm7P8kai1MBi+roi65SA/\nRMtGUwskfqijWGACn/vHbPjOhnPmB/vMDAPPx1pnnb0/+7P3fp8Pm3nN3ufsOZFSQpKk/f6pqwuQ\nJB1ZDAZJUo7BIEnKMRgkSTkGgyQpx2CQJOUYDJKkHINBkpRjMEiScnp0dQGHo3///mnIkCFdXYYk\ndStr1qzZkVI6ubV+3TIYhgwZQn19fVeXIUndSkS83JZ+XkqSJOUUCoaI6BcRyyOiIXvuW6ZfTdan\nISJqmrXPjIgNEfFMRHyjSC2SpMooesYwD6hLKQ0F6rL5nIjoB3wZ+BdgLPDliOgbEe8BFgATUkrn\nAQMiYkLBeiRJBRUNhmnAkmx6CTC9RJ8pwPKU0msppdeB5cCHgbOAP6aUtmf9VgCXF6xHklRQ0WAY\nkFLaApA9n1KizyDgL83mN2VtzwPnRMSQiOhBU6j8c7kdRcTsiKiPiPrt27eX6yZJKqjVTyVFxArg\n1BKLbmrjPqJEW0opvR4RnwdqgX3Ar2k6iygppbQIWARQXV3ttwtJUgdpNRhSShPLLYuIrRExMKW0\nJSIGAttKdNsEjG82fzrwRLbtR4FHs23NBva2uXJJUocoeinpEWD/p4xqgKUl+jwOTM7ecO4LTM7a\niIhTsue+wP8AFhesR5JUUNFgmA9MiogGYFI2T0RUR8RigJTSa8D/Bp7MHrdlbQDfjohngdXA/JTS\nHwvWI0kqKFLqfpfrq6urk3c+S1L7RMSalFJ1a/2881mSlGMwSJJyDAZJUo7BIEnKMRgkSTkGgyQp\nx2CQJOUYDJKkHINBkpRjMEiScgwGSVKOwSBJyjEYJEk5BoMkKcdgkCTlGAySpByDQZKUYzBIknIM\nBklSjsEgScoxGCRJOQaDJCmnUDBERL+IWB4RDdlz3zL9lkVEY0Q8dlD7mRHx22z92og4rkg9kqTi\nip4xzAPqUkpDgbpsvpQFwFUl2r8O3JGt/zrwbwXrkSQVVDQYpgFLsuklwPRSnVJKdcDO5m0REcCl\nwAOtrS9J6jxFg2FASmkLQPZ8SjvWfQ/QmFLak81vAgYVrEeSVFCP1jpExArg1BKLbiq47yjRllqo\nYzYwG2Dw4MEFdy1JKqfVYEgpTSy3LCK2RsTAlNKWiBgIbGvHvncAfSKiR3bWcDrwSgt1LAIWAVRX\nV5cNEElSMUUvJT0C1GTTNcDStq6YUkrAfwBXHM76kqSOUTQY5gOTIqIBmJTNExHVEbF4f6eIWAXc\nD0yIiE0RMSVbdAPwPyPieZrec/h+wXokSQW1eimpJSmlV4EJJdrrgVnN5i8us/6fgLFFapAkVZZ3\nPkuScgwGSVKOwSBJyjEYJKkL9e7duyLbeeKJJ7jssssqsi2DQZKUYzBI0hEgpcTcuXM5//zzGT58\nOLW1tcChZwLXXXcdP/zhDwFYtmwZ55xzDhdddBEPPfRQxWop9HFVSVJlPPTQQ6xbt47169ezY8cO\nxowZw7hx48r23717N1dffTUrV67k7LPPZubMmRWrxTMGSepkD6/dzAfnr+TMeT9j1zt7eXjtZn71\nq19x5ZVXUlVVxYABA7jkkkt48skny27jD3/4A2eeeSZDhw4lIvjkJz9ZsfoMBknqRA+v3cyNDz3N\n5sZdJCAluPGhp3l+686S/Xv06MG+ffsOzO/evfvAdNO3F1SewSBJnWjB48+x6529ubZd7+yl4Z/+\nmdraWvbu3cv27dv55S9/ydixYznjjDN49tlnefvtt3njjTeoq6sD4JxzzuHFF1/khRdeAOAnP/lJ\nxWr0PQZJ6kSvNO4q2b570AWMGPgWI0eOJCL4xje+wamnNn3jwcc//nFGjBjB0KFDGT16NADHH388\nixYtYurUqfTv35+LLrqIjRs3VqTGaPojp91LdXV1qq+v7+oyJKndPjh/JZtLhMOgPr1YPe/SDt13\nRKxJKVW31s9LSZLUieZOGUavnlW5tl49q5g7ZVgXVXQoLyVJUieaPrrpG4wXPP4crzTu4rQ+vZg7\nZdiB9iOBwSBJnWz66EFHVBAczEtJkqQcg0GSlGMwSJJyDAZJUo7BIEnKMRgkSTkGgyQpp1AwRES/\niFgeEQ3Zc98y/ZZFRGNEPHZQ+3UR8XxEpIjoX6QWSVJlFD1jmAfUpZSGAnXZfCkLgKtKtK8GJgIv\nF6xDklQhRYNhGrAkm14CTC/VKaVUBxzyx8ZTSmtTSi8VrEGSVEFFg2FASmkLQPZ8SvGSJEldqdW/\nlRQRK4BTSyy6qfLltFjHbGA2wODBgztz15J0TGk1GFJKE8sti4itETEwpbQlIgYC2ypaXb6ORcAi\naPo+ho7ajyQd64peSnoEqMmma4ClBbcnSepiRYNhPjApIhqASdk8EVEdEYv3d4qIVcD9wISI2BQR\nU7L26yNiE3A6sKH5OpKkruFXe0rSMcKv9pQkHRaDQZKUYzBIknIMBklSjsEgScoxGCRJOQaDJCnH\nYJAk5RgMkqQcg0GSlGMwSJJyDAZJUo7BIEnKMRgkSTkGgyQpx2CQJOUYDJKkHINBkpRjMEiScgwG\nSVKOwSBJyjEYJEk5hYIhIvpFxPKIaMie+5bptywiGiPisYPa742I5yJiY0T8ICJ6FqlHklRc0TOG\neUBdSmkoUJfNl7IAuKpE+73AOcBwoBcwq2A9kqSCigbDNGBJNr0EmF6qU0qpDthZov3nKQP8Dji9\nYD2SpIKKBsOAlNIWgOz5lMPZSHYJ6SpgWcF6JEkF9WitQ0SsAE4tseimCtbxf4BfppRWtVDHbGA2\nwODBgyu4a0lSc60GQ0ppYrllEbE1IgamlLZExEBgW3sLiIgvAycD17RSxyJgEUB1dXVq734kSW1T\n9FLSI0BNNl0DLG3PyhExC5gCXJlS2lewFklSBRQNhvnApIhoACZl80REdUQs3t8pIlYB9wMTImJT\nREzJFn0XGAD8JiLWRcQtBeuRJBXU6qWklqSUXgUmlGivp9lHT1NKF5dZv9D+JUmV553PkqQcg0GS\nlGMwSJJyDAZJUo7BIEnKMRgkSTkGgyQpx2CQJOUYDJKkHINBkpRjMEiScgwGSVKOwSBJyjEYJEk5\nBoMkKcdgkCTlGAySpByDQZKUYzBIknIMBklSjsEgScoxGCRJOQaDJCmnUDBERL+IWB4RDdlz3zL9\nlkVEY0Q8dlD79yNifURsiIgHIqJ3kXokScUVPWOYB9SllIYCddl8KQuAq0q0fzGlNDKlNAL4M3Bd\nwXokSQUVDYZpwJJsegkwvVSnlFIdsLNE+5sAERFALyAVrEeSVFDRYBiQUtoCkD2f0t4NRMQ9wF+B\nc4C7Wug3OyLqI6J++/bth1uvJKkVrQZDRKyIiI0lHtMqUUBK6TPAacDvgZkt9FuUUqpOKVWffPLJ\nldi1JKmEHq11SClNLLcsIrZGxMCU0paIGAhsO5wiUkp7I6IWmAvcczjbkCRVRtFLSY8ANdl0DbC0\nrStGk7P3TwP/DfhDwXokSQUVDYb5wKSIaAAmZfNERHVELN7fKSJWAfcDEyJiU0RMAQJYEhFPA08D\nA4HbCtYjSSqo1UtJLUkpvQpMKNFeD8xqNn9xmU18sMj+JUmV553PkqQcg0GSlGMwSJJyDAZJUo7B\nIEnKMRgkSTkGgyQpx2CQJOUYDJKkHINBkpRjMOioN2vWLJ599lkAhgwZwo4dO7q4IunIVuhvJUnd\nweLFi1vvJOkAzxg6QH19Pddff32LfdatW8fPf/7zTqro2PG3v/2NqVOnMnLkSM4//3xqa2sZP348\n9fX1h/T98Y9/zNixYxk1ahTXXHMNe/fuBaB3797cdNNNjBw5kgsvvJCtW7cCsHXrVmbMmMHIkSMZ\nOXIkv/71r1vcjtRdGQwdoLq6mjvvvLPFPgZDx1i2bBmnnXYa69evZ+PGjXz4wx8u2e/3v/89tbW1\nrF69mnXr1lFVVcW9994LNIXLhRdeyPr16xk3bhzf+973ALj++uu55JJLWL9+PU899RTnnXdei9uR\nuiuDoY1uv/12hg0bxsSJE7nyyiv55je/mftNdMeOHQwZMgSAJ554gssuuwxo+iHz2c9+ljFjxjB6\n9GiWLl3KP/7xD2655RZqa2sZNWoUtbW1XfWyjjrDhw9nxYoV3HDDDaxatYqTTjqpZL+6ujrWrFnD\nmDFjGDVqFHV1dfzpT38C4Ljjjjvw73fBBRfw0ksvAbBy5Uo+//nPA1BVVcVJJ53U4nak7sr3GNpg\nzZo13Hfffaxdu5Y9e/bwvve9jwsuuKBN695+++1ceuml/OAHP6CxsZGxY8cyceJEbrvtNurr67n7\n7rs7uPqj38NrN7Pg8ed4pXEXp/XpxW33PEpsWseNN97I5MmTS66TUqKmpoavfe1rhyzr2bMnTV8q\n2BQAe/bsKbvvlrYjdVeeMbTBqlWrmDFjBu9+97s58cQT+ehHP9rmdX/xi18wf/58Ro0axfjx49m9\nezd//vOfO7DaY8vDazdz40NPs7lxFwl4+S+b+Orjf6L3eR9izpw5PPXUUyXXmzBhAg888ADbtjV9\nTflrr73Gyy+/3OK+JkyYwMKFCwHYu3cvb7755mFtRzrSecZQRvPfQtnYwNjTjjukT48ePdi3bx8A\nu3fvLrmdlBIPPvggw4YNy7X/9re/rXzRx6AFjz/Hrnf+883ed7a/xIv338MnllRx7qC+LFy4kDlz\n5hyy3rnnnstXv/pVJk+ezL59++jZsyff+c53OOOMM8ru69vf/jazZ8/m+9//PlVVVSxcuJD3v//9\n7d6OdKQzGErY/1vo/h84b/f/ryxd+i1qP3MtHzl/AI8++ijXXHMNQ4YMYc2aNYwdO5YHHnig5Lam\nTJnCXXfdxV133UVEsHbtWkaPHs0JJ5zAzp07O/NlHZVeadyVm+911gX0OusCAnhy/lSg6T2f/fa/\nXwAwc+ZMZs6cecg233rrrQPTV1xxBVdccQUAAwYMYOnSpYf0L7cdqbvyUlIJB/8W+q5Tz6bXsIv5\n9Ec/xOWXX87FFzd9hfWcOXNYuHAhH/jAB8reNHXzzTfzzjvvMGLECM4//3xuvvlmAD70oQ/x7LPP\n+uZzQaf16dWudkmti5RSV9fQbtXV1anU59Ir5cx5P6PUqATw4vyp3HrrrfTu3bvkJQp1roPP7gB6\n9azia/86nOmjB3VhZSrllltuYdy4cUycOLGrSzkmRcSalFJ1a/28lFTCaX16sfmgSxT723Vk2f/D\nv/mnkuZOGWYoHKFuu+22ri5BbVDoUlJE9IuI5RHRkD33LdNvWUQ0RsRjZZbfFRFvlVrWFeZOGUav\nnlW5tl49q5g7pekN5FtvvdWzhSPI9NGDWD3vUl6cP5XV8y41FDrRSy+9xHvf+16uvvpqzjvvPCZP\nnsyuXbtYt24dF154ISNGjGDGjBm8/vrrAHz6058+8H7cvHnzOPfccxkxYsSB/0/bt2/n8ssvZ8yY\nMYwZM4bVq1d32Ws7lhV9j2EeUJdSGgrUZfOlLACuKrUgIqqBPgXrqKjpowfxtX8dzqA+vQhgUJ9e\nXpqQymhoaODaa6/lmWeeoU+fPjz44IN86lOf4utf/zobNmxg+PDhfOUrX8mt89prr/HTn/6UZ555\nhg0bNvClL30JgC984Qt88Ytf5Mknn+TBBx9k1qxZXfGSjnlFLyVNA8Zn00uAJ4AbDu6UUqqLiPEH\nt0dEFU2h8d+BGQVrqajpowcZBFIbnHnmmYwaNQpoulP8hRdeoLGxkUsuuQSAmpoaPvaxj+XWOfHE\nEzn++OOZNWsWU6dOPXCn+YoVKw78JVyAN998k507d3LCCSd00qsRFA+GASmlLQAppS0RcUo7178O\neCRbt2ApkjrL/vt8Xn75JV7buYeH125m+uhBVFVV0djY2Or6PXr04He/+x11dXXcd9993H333axc\nuZJ9+/bxm9/8hl69fD+vK7V6KSkiVkTExhKPaUV2HBGnAR8D7mpj/9kRUR8R9du3by+ya0kFNL/b\nHGDP3n3c+NDTPLx2MwAnnXQSffv2ZdWqVQD86Ec/OnD2sN9bb73FG2+8wUc+8hG+9a1vsW7dOgAm\nT56c+zMx+9vVuVo9Y0gplf1cWURsjYiB2W/8A4Ft7dj3aOBs4PnsbOHdEfF8SunsMnUsAhZB08dV\n27EfSRV08H0+ALve2cuCx59jRvYTZcmSJXzuc5/j73//O2eddRb33HNPrv/OnTuZNm0au3fvJqXE\nHXfcAcCdd97Jtddey4gRI9izZw/jxo3ju9/9bqe8Lv2nQvcxRMQC4NWU0vyImAf0Syn9rzJ9xwNz\nUkqXlVn+Vkqpd1v229H3MUgqr7X7fHTkaut9DEU/lTQfmBQRDcCkbJ6IqI6IA1+bFRGrgPuBCRGx\nKSKmFNyvpC7i3eZHv0JvPqeUXgUmlGivB2Y1m7+4Ddtq09mCpK41d8qwkneb77/PR92fdz5Lahfv\nNj/6GQyS2s37fI5u/nVVSVKOwSBJyjEYJEk5BoMkKcdgkCTlGAySpByDQZKUYzBIknIMBklSjsEg\nScoxGCRJOQaDJCnHYJAk5RgMkqQcg0GSlGMwSJJyDAZJUo7BIEnKMRgkSTkGgyQpp1AwRES/iFge\nEQ3Zc98y/ZZFRGNEPHZQ+w8j4sWIWJc9RhWpR5JUXNEzhnlAXUppKFCXzZeyALiqzLK5KaVR2WNd\nwXokSQUVDYZpwJJsegkwvVSnlFIdsLPgviRJnaBoMAxIKW0ByJ5POYxt3B4RGyLijoh4V8F6JEkF\n9WitQ0SsAE4tseimCuz/RuCvwHHAIuAG4LYydcwGZgMMHjy4AruWJJXSajCklCaWWxYRWyNiYEpp\nS0QMBLa1Z+f7zzaAtyPiHmBOC30X0RQeVFdXp/bsR5LUdkUvJT0C1GTTNcDS9qychQkRETS9P7Gx\nYD2SpIKKBsN8YFJENACTsnkiojoiFu/vFBGrgPuBCRGxKSKmZIvujYingaeB/sBXC9YjSSqo1UtJ\nLUkpvQpMKNFeD8xqNn9xmfUvLbJ/SVLleeezJCnHYJAk5RgMkqQcg0GSlGMwSJJyDAZJUo7BIEnK\nMRgkSTkGgyQpx2CQJOUYDJKkHINBkpRjMEiScgwGSVKOwSBJyjEYJEk5BoMkKcdgkCTlGAySpJxI\nKXV1De0WEduBl4H+wI4uLudI4ngcyjHJczzyjrXxOCOldHJrnbplMOwXEfUppequruNI4XgcyjHJ\nczzyHI/SvJQkScoxGCRJOd09GBZ1dQFHGMfjUI5JnuOR53iU0K3fY5AkVV53P2OQJFXYER8MEdEv\nIpZHREP23LdEn1ER8ZuIeCYiNkTEzGbLfhgRL0bEuuwxqnNfQWVVYDzOjIjfZuvXRsRxnfsKKqst\n45H1WxYRjRHx2EHtx9zxkfUrNx5H1fEB7RqTmqxPQ0TUNGt/IiKea3aMnNJ51XeNIz4YgHlAXUpp\nKFCXzR/s78CnUkrnAR8GvhURfZotn5tSGpU91nV8yR2q6Hh8HbgjW/914N86oeaO1JbxAFgAXFVm\n2bF2fED58Tjajg9ow5hERD/gy8C/AGOBLx8UIJ9odoxs64yiu1J3CIZpwJJsegkw/eAOKaU/ppQa\nsulXgG1AqzdxdFOHPR4REcClwAMtrd/NtDoeACmlOmBnZxXVhQ57PI7S4wPaNiZTgOUppddSSq8D\ny2n6peqY1B2CYUBKaQtA9tziaVxEjAWOA15o1nx7dknljoh4V8eV2imKjMd7gMaU0p5s8SZgUAfW\n2hnaNR5lHLPHx0GOxuMD2jYmg4C/NJs/+LXfk11GujkL0KNaj64uACAiVgCnllh0Uzu3MxD4EVCT\nUtqXNd8I/JWmH46LgBuA2w6/2o7XUeNR5oA+4j+WVqnxKOOYPT5KbbpE2xF/fEBFxqSl1/6JlNLm\niDgBeJCmS3D/3v4qu48jIhhSShPLLYuIrRExMKW0JftBV/L6XkScCPwM+FJK6f812/aWbPLtiLgH\nmFPB0jtEB47HDqBPRPTIfis8HXilwuVXXCXGo4VtH5PHRxnd8viAiozJJmB8s/nTgSeybW/OnndG\nxP+l6T2IozoYusOlpEeA/Z8QqAGWHtwh++TET4F/Tyndf9Cygdlz0HRtcWOHVtvxDns8UtNNK/8B\nXNHS+t1Mq+PRkmPx+CjnKD0+oG1j8jgwOSL6Zm86TwYej4geEdEfICJ6ApfR/Y+R1qWUjugHTdc9\n64CG7Llf1l4NLM6mPwm8A6xr9hiVLVsJPE3TP+aPgd5d/Zq6eDzOAn4HPA/cD7yrq19TR49HNr8K\n2A7soum3wynH6vHRyngcVcdHO8fks9nrfh74TNb2X4A1wAbgGeDbQFVXv6aOfnjnsyQppztcSpIk\ndSKDQZKUYzBIknIMBklSjsEgScoxGCRJOQaDJCnHYJAk5fx/z1a+UHy1uVsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1969cfe60f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w1 = 'loud'\n",
    "w2 = 'quiet'\n",
    "w3 = 'noise'\n",
    "w4 = 'silence'\n",
    "\n",
    "visualize_weights(w1, w2, w3, w4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlenv]",
   "language": "python",
   "name": "conda-env-mlenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
